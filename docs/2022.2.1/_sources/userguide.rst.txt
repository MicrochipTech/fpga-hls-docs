.. highlight:: c

.. _userguide:

User Guide
=================

Introduction to High-Level Synthesis
--------------------------------------

High-level synthesis (HLS) refers to the synthesis of a hardware circuit from a software program specified in a high-level language, where the hardware circuit performs the same functionality as the software program.  For SmartHLS, the input is a C/C++-language program, and the output is a circuit specification in the Verilog hardware description language.  The SmartHLS-generated Verilog can be given to Libero to be programmed on a Microchip FPGA. The underlying motivation for HLS is to raise the level of abstraction for hardware design, by allowing software methodologies to be used to design hardware.  This can help to shorten design cycles, improve design productivity and reduce time-to-market.

While a detailed knowledge of HLS is not required to use SmartHLS, it is worthwhile to highlight the key steps involved in converting software to hardware. The four main steps involved in HLS are allocation, scheduling, binding, and RTL generation, which runs one after another (i.e., binding runs after scheduling is done).   

* Allocation: The allocation step defines the constraints on the generated hardware, including the number of hardware resources of a given type that may be used (e.g. how many divider units may be used, the number of RAM ports, etc.), as well as the target clock period for the hardware, and other user-supplied constraints.
* Scheduling: Software programs are written without any notion of a clock or finite state machine (FSM). The scheduling step of HLS bridges this gap, by assigning the computations in the software to occur in specific clock cycles in hardware. With the user-provided target clock period constraint (e.g. 10 ns), scheduling will assign operations into clock cycles such that the operations in each cycle does not exceed the target clock period, in order to meet the user constraint. In addition, the scheduling step will ensure that the data-dependencies between the operations are met.  
* Binding: While a software program may contain an arbitrary number of operations of a given type (e.g. multiplications), the hardware may contain only a limited number of units capable of performing such a computation.  The binding step of HLS is to associate (bind) each computation in the software with a specific unit in the hardware.
* RTL generation: Using the analysis from the previous steps, the final step of HLS is to generate a description of the circuit in a hardware description language (Verilog).

Executing computations in hardware brings speed and energy advantages over performing the same computations in software running on a processor.  The underlying reason for this is that the hardware is dedicated to the computational work being performed, whereas a processor is generic and has the inherent overheads of fetching/decoding instructions, loading/storing from/to memory, etc.  Further acceleration is possible by exploiting hardware parallelism, where computations can concurrently.  With SmartHLS, one can exploit four styles of hardware parallelism, which are instruction-level, loop-level, thread-level, and function-level parallelism.

Instruction-level Parallelism
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Instruction-level parallelism refers to the ability to concurrently execute computations for instructions concurrently by analyzing data dependencies.  Computations that do not depend on each other can be executed at the same time.  Consider the following code snippet which performs three addition operations.

.. code-block:: bash

	z = a + b;
	x = c + d;
	q = z + x;
	...

Observe that the first and second additions do not depend on one another.  These additions can therefore be executed concurrently, as long as there are two adder units available in the hardware.  SmartHLS automatically analyzes the dependencies between computations in the software to exploit instruction-level parallelism in the generated hardware. The user does not need to do anything. In the above example, the third addition operation depends on the results of the first two, and hence, its execution cannot be done in parallel with the others. Instruction-level parallelism is referred to as fine-grained parallelism, as concurrency is achieved at a fine-grained level (instruction-level) of granularity.

Loop-level Parallelism
~~~~~~~~~~~~~~~~~~~~~~~~

In software, the majority of runtime can be spent on loops, where loop iterations execute sequentially.  That is, loop iteration *i* needs to finish before iteration *i + 1* can start. With SmartHLS, it is possible to overlap the execution of a loop iteration with another iterations using a technique called *loop pipelining* (see :ref:`loop_pipelining`). Now, imagine a loop with *N* iterations, where each iteration takes 100 clock cycles to complete.  In software, this loop would take *100N* clock cycles to execute. With loop pipelining in hardware, the idea is to execute a portion of a loop iteration *i* and then commence executing iteration *i + 1* even before iteration *i* is complete. If loop pipelining can commence a new loop iteration *every* clock cycles, then the total number of clock cycles required to execute the entire loop be *N + (N-1)* cycles -- a significant reduction relative to *100N*. The (N-1) cycles is because each successive loop iteration start 1 cycle after the previous iteration, hence the last loop starts after (N-1) cycles.

A user can specify a loop to be pipelined with the use of the loop pipeline pragma. By default, a loop is not pipelined automatically.

Thread-level Parallelism
~~~~~~~~~~~~~~~~~~~~~~~~~~

Modern CPUs have multiple cores that can be used to concurrently execute multiple threads in software. Threads are widely used in C/C++, where, parallelism is realized at the granularity of entire C/C++ functions.  Hence thread-level parallelism is referred to as coarse-grained parallelism since one or more functions execute in parallel.  SmartHLS supports hardware synthesis of ``hls::threads``, where concurrently executing threads in software are synthesized into concurrently executing hardware units (see :ref:`pthreads_multithreading`).  This allows a software developer to take advantage of spatial parallelism in hardware using a familiar parallel programming paradigm in software.  Moreover, the parallel execution behaviour of threads can be debugged in software, it is considerably easier than debugging in hardware.

In a multi-threaded software program, synchronization between the threads can be important, with the most commonly used synchronization constructs being mutexes and barriers. SmartHLS supports the synthesis of mutexes and barriers into hardware.

Data Flow (Streaming) Parallelism
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The second style of coarse-grained parallelism is referred to as *data flow* parallelism.  This form of parallelism arises frequently in *streaming* applications, and are commonly used for video/audio processing, machine learning, and computational finance.  In such applications, there is a stream of input data that is fed into the application at regular intervals.  For example, in an audio processing application, a digital audio sample may be given to the circuit every clock cycle.  In streaming applications, a succession of computational tasks is executed on the stream of input data, producing a stream of output data.  For example, the first task may be to filter the input audio to remove high-frequency components.  Subsequently, a second task may receive the filtered audio, and boost the bass low-frequency components.  Observe that, in such a scenario, the two tasks may be overlapped with one another.  Input samples are continuously received by the first task and given to the second task.

SmartHLS provides a way for a developer to specify data flow parallelism through the use of function pipelining (see :ref:`function_pipelining`) and/or threads (see :ref:`data_flow_parallelism_with_pthreads`) with SmartHLS's FIFO library (see :ref:`streaming_lib`) used to connect the streaming modules.



SmartHLS Overview
------------------

SmartHLS accepts a C/C++ software program as input and automatically generates hardware described in Verilog HDL (hardware description language) that can be programmed onto a Microchip FPGA.
The generated hardware can be imported as an HDL+ component into SmartDesign with a Tcl script that is also generated by SmartHLS. SmartHLS also generates a C++ accelerator driver API that can
be used to control the generated hardware from an embedded processor. Optionally, SmartHLS can combine user code with the accelerator driver API and cross-compile it into a binary that can run
on a RISC-V processor in an SoC design.

.. image:: /images/smarthls_flow_soc.png
        :align: center

.. SmartHLS has two different synthesis *flows*:
 * Hardware Flow: Synthesizes the whole C program (or user-specified C functions) into a hardware circuit.
 * Processor-Accelerator Hybrid Flow: Synthesize the whole C program into a processor-accelerator SoC (System-on-chip).

.. Hardware Flow
.. ---------------

.. SmartHLS's hardware flow synthesizes a C program into a hardware circuit (without a processor).
.. One can compile the entire C program, or specific functions of the program, into hardware.

In a software program, user first needs to specify a top-level function (during project creation in the SmartHLS IDE or in the source code with our pragma, ``#pragma HLS function top`` ). Please refer to the :ref:`custom_top_level` section for more details specifying the top-level function.

Then the following button, ``Compile Software to Hardware`` can be clicked to compile software to hardware:

.. image:: /images/icon_hardware_flow.png
        :align: center

This will compile the top-level function and all of its descendant functions into hardware.
The rest of the program (outside the top-level function) is considered as the software testbench, to give inputs into the top-level function and verify outputs from the top-level function (and its descendants). 
The software testbench is used to automatically generate the RTL testbench and stimulus for `SW/HW Co-Simulation`_.

Alongside the generated hardware, the ``Compile Software to Hardware`` button will also generate :ref:`C++ driver functions<accelerator_driver>`, which can be combined with the software testbench and to produce code that can run
on the processor in an SoC system and control the generated hardware. There are also optional SoC-related features offered by SmartHLS, such as generation of a reference SoC and automatic combination and cross-compilation of
the software testbench and accelerator drivers for that reference SoC. 


SmartHLS SoC Flow
------------------

SmartHLS can automatically generate a RISC-V processor/accelerator SoC for the PolarFire\ :sup:`®`\  SoC device on the Icicle Kit. For more information on the SoC features, see :ref:`soc_features`.

.. NOTE::

    This feature is specific to SmartHLS SoC early access program (EAP), and requires a separate SmartHLS EAP license. If you are interested in participating in the EAP, please email SmartHLS@microchip.com.

.. Processor-Accelerator Hybrid Flow
.. ------------------------------
.. 
.. SmartHLS can automatically compile a C program into a complete processor-accelerator SoC
.. comprising an ARM processor and one or more hardware accelerators.
.. One can designate C functions to be compiled to hardware accelerators and SmartHLS
.. will automatically partition the program so that the remaining program segments are executed on the ARM processor.
.. The communication between the processor and hardware accelerators, as well as the generation of the system interconnect,
.. are automatically handled by SmartHLS.
.. 
.. To accelerate a function, you can specify the function name in the ``config.tcl`` file
.. as shown below::
.. 
..     set_accelerator_function "function_name"
.. 
.. Then run ``shls hybrid`` in command line, which generates the complete system.
.. The architecture of a processor-accelerator hybrid system is described in :ref:`hwarch`.
.. 
.. Enhanced Data Transfer for Hybrid Systems Targetting Microchip
.. ~~~~~~~~~~~~~~~~~~~~~~
.. 
.. SmartHLS provides enhanced data transfer methods for the Hybrid Systems targeting
.. Microchip's PolarFire\ :sup:`®`\  SoC FPGA.  Three data transfer methods are supported for
.. the RISC-V processor to handoff or retrieve data to/from SmartHLS accelerators:
.. 
.. * ``cpu_driven``: the RISC-V processor is the 'master' of the data transfer and
..   writes or reads to/from the SmartHLS accelerators directly. The data transfer
..   takes place through the connection between the processor's AXI4 master
..   interface and the accelerators' AXI4 slave interfaces, via an AXI4
..   interconnect.
..   The ``cpu_driven`` transfer method has lower transfer throughput than the two
..   methods below, but has the best latency if the transfer data is present in
..   the processor cache. This transfer method is most suitable for transferring
..   small data, such as writing scalar arguments to the accelerator or retrieving
..   return value from the accelerator.
.. 
.. * ``copy``: when ``copy`` transfer method is used for a data (e.g., a C/C++ array),
..   an on-chip buffer is automatically created inside the accelerator to store a
..   copy of the transferring data. The data transfer will be performed by a DMA
..   engine which is automatically added to the SoC by SmartHLS.  Input data is
..   DMA-transferred from the main memory to the accelerator's on-chip buffer
..   before the accelerator starts execution; output data is transferred in the
..   reversed direction after the accelerator finishes execution; and for in/out
..   data, the transfer is performed both before and after accelerator execution
..   in the respective directions.
..   The ``copy`` transfer method exhibits the highest data transfer throughput
..   and is suitable for transferring large data, especially the ones that are
..   frequently accessed by the accelerator.
.. 
.. * ``direct``: the SmartHLS accelerator acts as the 'master' and directly accesses
..   the data in the main memory. The transfer is done through the connection from
..   the accelerator's AXI4 master interface to the main memory's AXI4 slave
..   interface, via an AXI4 interconnect.
..   Such transfer method is most suitable for infrequent accesses of small data,
..   or a small number of random accesses of a large dataset.
..   For example, an accelerator may need to look up only one value from a large
..   hash table, but the hash key is only computed during the accelerator
..   execution, making it infeasible to determine which hash table entry would be
..   read prior to the accelerator's execution.  In this case, using ``copy``
..   transfer to prefetch the entire hash table to the accelerator's on-chip
..   buffer would be wasteful in terms of RAM resources as well as performance.
..   ``direct`` transfer becomes the most suitable option in this case.
.. 
.. When an accelerator uses ``direct`` or ``copy`` transfer method, the
.. processor's data cache is always flushed before starting the accelerator's
.. execution to guarantee cache coherency.
.. 
.. The table below shows the default and available data transfer methods for each
.. type of data accessed by an accelerator function,
.. 
.. +------------------------+--------------------------------------------------+
.. | Data Type              | Transfer Methods                                 |
.. +========================+==================================================+
.. | Scalar argument        | ``cpu_driven`` transfer method is always used.   |
.. +------------------------+--------------------------------------------------+
.. | Pointer argument       | All transfer methods are available.              |
.. | (incl. array)          | Default: ``copy``                                |
.. +------------------------+--------------------------------------------------+
.. | Global variables       | ``direct`` transfer method is always used.       |
.. +------------------------+--------------------------------------------------+
.. | Return value           | ``cpu_driven`` transfer method is always used.   |
.. +------------------------+--------------------------------------------------+
.. 
.. When compiling the input C/C++ source code to generate a hybrid system, SmartHLS
.. will automatically determine the direction (input/output/inout) and data size
.. for each argument of the accelerator function, and apply the default transfer
.. method according to the above table.
.. 
.. Users can also overwrite the default behaviour in the ``config.tcl`` file using
.. the command below::
.. 
..     config_accelerator_function_arg "function_name" "argument_name"   \
..         [-size <SIZE_IN_BYTES>]                                       \
..         [-direction <input|output|inout>]                             \
..         [-transfer_type <cpu_driven|copy|direct>]
.. 
.. After running ``shls hybrid`` command to generate the complete SoC system,
.. users can find a summary table from ``hls_output/reports/summary.hls.<top_level>.rpt``
.. like below::
.. 
..   ====== 4. Accelerator Information ======
.. 
..   +-------------------------------------------------------------------------------+
..   | Accelerator Function: DmaTestDut (Address Space: 0x60002500 - 0x600025a0)     |
..   +-------------------+----------------+--------------+-----------+---------------+
..   | Argument          | Address Offset | Size [Bytes] | Direction | Transfer Type |
..   +-------------------+----------------+--------------+-----------+---------------+
..   | in_8_bit_scalar   | 0xc            | 4            | input     | cpu_driven    |
..   | in_16_bit_scalar  | 0x10           | 4            | input     | cpu_driven    |
..   | in_32_bit_scalar  | 0x14           | 4            | input     | cpu_driven    |
..   | in_64_bit_scalar  | 0x18           | 8            | input     | cpu_driven    |
..   | in_8_bit          | 0x30           | 16           | input     | copy          |
..   | in_16_bit         | 0x20           | n/a          | input     | direct        |
..   | in_32_bit         | 0x40           | 16           | input     | copy          |
..   | in_64_bit         | 0x24           | n/a          | input     | direct        |
..   | out_8_bit         | 0x28           | n/a          | output    | direct        |
..   | out_16_bit        | 0x50           | 16           | output    | copy          |
..   | out_32_bit        | 0x2c           | n/a          | output    | direct        |
..   | out_64_bit        | 0x60           | 16           | output    | copy          |
..   | cpu_driven_8_bit  | 0x70           | 16           | inout     | cpu_driven    |
..   | cpu_driven_16_bit | 0x80           | 16           | inout     | cpu_driven    |
..   | cpu_driven_32_bit | 0x90           | 16           | inout     | cpu_driven    |
..   +-------------------+----------------+--------------+-----------+---------------+
.. 
..   All arguments with "copy" transfer type use a DMA to transfer the data.
..   DMA Address Space: 0x60002000 - 0x60002470
.. 
 
.. LLVM IR Input Flow
.. --------------

.. By default SmartHLS accepts C/C++ as input. However, some advanced users may wish to 
.. input LLVM intermediate representation directly into SmartHLS.
.. SmartHLS's LLVM IR flow synthesizes LLVM intermediate representation code into a hardware circuit. 
.. You can compile an LLVM IR into a hardware circuit by specifying an LLVM IR file
.. (either a .ll or .bc file) using the INPUT_BITCODE variable inside the makefile of your project::

..    INPUT_BITCODE=input.ll

.. _smarthls_pragmas:

SmartHLS Pragmas
----------------------

Pragmas can be applied to the software code by the user to apply HLS optimization techniques and/or guide the compiler for hardware generation. 
They are applied directly on the applicable software construct (i.e., function, loop, argument, array) to specify a certain optimization for them. For example, to apply pipelining on a loop::

    #pragma HLS loop pipeline
    for (i = 1; i < N; i++) {
        a[i] = a[i-1] + 2
    }

For more details on the supported pragmas, please refer to :ref:`pragmas`. 
For more details on loop pipelining, please refer to :ref:`loop_pipelining`. 

.. _smarthls_constraints:

SmartHLS Constraints
----------------------

SmartHLS also supports user constraints to guide hardware generation. 
Whereas pragmas are applied directly on the source code for optimizations that are specific and local to the software construct that it is being applied on (function, loop, memory, argument, etc), 
constraints are used for settings that will be globally applied to the entire program (i.e., setting the target FPGA, target clock period). 
Each project specifies its constraints in the ``config.tcl`` file in the project directory.
This file is automatically generated by the SmartHLS IDE. To modify the constraints, click the ``HLS Constraints`` button:

.. image:: /images/icon_constraints.png
        :align: center

The following window will open:

.. image:: /images/empty_constraint_setting_window.png
        :scale: 75 %
        :align: center

You can add, edit, or remove constraints from this window.
Select a constraint type from the first drop-down menu. If you want more information about
a constraint, click the Help button, which will open the corresponding :ref:`constraints` page.

An important constraint is the target clock period (shown as ``Set target clock period`` in the drop-down menu).
With this constraint, SmartHLS schedules the operations of a program to meet the specified clock period.
When this constraint is not given, SmartHLS uses the default clock period for each device, as shown below.

============  ===========================  =================================  =============================
FPGA Vendor       Device                      Default Clock Frequency (MHz)      Default Clock Period (ns)
============  ===========================  =================================  =============================
Microchip        PolarFire                       100                                10
Microchip        SmartFusion2                    100                                10
============  ===========================  =================================  =============================

Details of all SmartHLS constraints are given in the :ref:`constraints`.

.. _custom_top_level:

Specifying the Top-level Function
----------------------------------

When compiling software to hardware with SmartHLS, you must specify the top-level function for your program.
Then SmartHLS will compile the specified top-level function and all of its descendant functions to hardware.
The remainder of the program (i.e., parent functions of the top-level function, typically the ``main`` function) 
becomes a software testbench that is used for :ref:`sw_hw_cosimulation`.
The top-level function is specified with the pragma, ``#pragma HLS function top``, directly on the source code, below the function prototype, as shown below:
       

.. code-block:: c

    void hw_top(int a, int b) {
       #pragma HLS function top
       ...
       ...
    }



.. _sw_hw_cosimulation:

SW/HW Co-Simulation
----------------------------
The circuit generated by SmartHLS should be functionally equivalent to the input software. 
Users should not modify the generated Verilog, as it is overwritten every time SmartHLS runs.

SW/HW co-simulation can be used to verify that the generated hardware produces the same outputs for the same inputs as software. 
With SW/HW co-simulation, user does not have to write their own RTL testbench, as it is automatically generated. 
If user already has their own custom RTL testbench, one can optionally choose their custom RTL testbench (:ref:`custom_testbench`) and not use SW/HW co-simulation.

To use SW/HW co-simulation, the input software program will be composed of two parts,

* A top-level function (and its descendant functions) to be synthesized to hardware by SmartHLS,

* A C/C++ testbench (the parent functions of the top-level function, typically ``main()``) that invokes the top-level function with test inputs and verifies outputs.

SW/HW co-simulation consists of the following automated steps:

1. SmartHLS runs your software program and saves all the inputs passed to the top-level function.
2. SmartHLS automatically creates an RTL testbench that reads in the inputs from step 1 and passes them into the SmartHLS-generated hardware module.
3. ModelSim simulates the testbench and saves the SmartHLS-generated module outputs.
4. SmartHLS runs your software program again, but uses the simulation outputs as the output of your top-level function.

You should write your C/C++ testbench such that the ``main()`` function returns a 0 when all outputs from the top-level function are as expected and otherwise return a non-zero value. We use this return value to determine whether the SW/HW co-simulation has passed.
In step 1, we verify that the program returns 0.
In step 4, we run the program using the outputs from simulation and if the SmartHLS-generated circuit matches the C program then ``main()`` should still return 0.

If the C/C++ program matches the RTL simulation then you should see: ``SW/HW co-simulation: PASS``

For any values that are shared between software testbench and hardware functions (top-level and descendants), you can either pass in as arguments into the top-level function, or if it is a global variable, it can be directly accessed without being passed in as an argument. 
Any variables that are accessed by both software testbench and hardware functions will create an interface at the top-level module. 
For example, if there is an array that is initialized in the software testbench and is used as an input to the hardware function, you may pass the array as an argument into the top-level function, which will create a memory interface for the array in the hardware core generated by SmartHLS. 
Arguments into the top-level function can be constants, pointers, arrays, and FIFO data types. 
The top-level function can also have a return value.
Please refer to the included example in the SmartHLS IDE, ``C++ Canny Edge Detection (SW/HW Co-Simulation)``, as a reference. 

If a top-level argument is coming from a dynamically allocated array (e.g., malloc), the size of the array (in bytes) must be specified with our ``interface`` pragma (e.g., ``#pragma HLS interface argument(<arg_name>) depth(<int>)``). 
Please see the :ref:`pragma_interface_memory_argument` for more details. The sizes of arrays that are statically allocated do not need to be specified with the pragma, as SmartHLS will automatically determine them. 

For debugging purposes, SmartHLS converts any C ``printf``
statements into Verilog ``$write`` statements so that values printed during
software execution will also be printed during hardware simulation. This
allows easy verification of the correctness of the hardware circuit.  Verilog
``$write`` statements are unsynthesizable and will not affect the final FPGA
hardware.

To specify the arguments to be passed to the software testbench (i.e., ``int main(int argc, char *argv[])``), a Makefile argument ``PROGRAM_ARGUMENTS`` can be defined in a ``makefile.user`` file (you need to create the file in the SmartHLS project folder).
For example, if a software testbench takes in two arguments, an input BMP file and a golden output BMP file, you would specify the following in the ``makefile.user`` file,

  .. code-block:: c

      PROGRAM_ARGUMENTS = input_file.bmp golden_output_file.bmp

.. NOTE::

  Co-simulating multiple top-level modules:

  * Co-simulation supports verifying multiple top-level modules simultaneously. Each top-level module is verified solely based on the corresponding top-level function's input and expected output gathered from the software testbench. However the Co-simulation testbench will simulate all top-level modules simultaneously with the same clock.

  * If the user wants to verify a single top-level module, the ``top`` pragma should be only added for the desired function in the source code.

.. NOTE::

 Limitations:

 * When function pipelining is used, the top-level function cannot have array
   interfaces (array arguments or global arrays that are accessed from both SW
   testbench and HW functions).
 * When multi-threading is used (:ref:`pthreads_multithreading`), Co-Simulation
   can only support the case when all threads are joined in the functions where
   the threads are forked.  Free-running threads (that are continuously running
   and never joined) are not supported by SW/HW Co-Simulation.

.. _loop_pipelining:

Loop Pipelining
------------------------------

Loop pipelining is an optimization that can automatically extract
loop-level parallelism to create an efficient hardware pipeline.
It allows executing multiple loop iterations concurrently on the same pipelined hardware.

To use loop pipelining, the user needs to specify the loop pipeline pragma above the applicable loop::

    #pragma HLS loop pipeline
    for (i = 1; i < N; i++) {
        a[i] = a[i-1] + 2
    }

An important concept in loop pipelining is the *initiation interval (II)*, which is
the cycle interval between starting successive iterations of the loop.
The best performance and hardware utilization is achieved when II=1, which means
that successive iterations of the loop can begin every clock cycle.
A pipelined loop with an II=2 means that successive iterations of the loop
can begin every two clock cycles, corresponding to half of the throughput of an II=1 loop.

.. Comment out:
  If a loop contains neither resource constraints nor cross-iteration
  dependencies, then the initiation interval will be one.
   Furthermore, in this case we can use a standard scheduling approach, which
   will correctly schedule the loop into a feed-forward pipeline.

By default, SmartHLS always attempts to create a pipeline with an II=1.
However, this is not possible in some cases due to resource constraints or
cross-iteration dependencies. Please refer to :ref:`optimizationguide` on more examples and details on loop pipelining. 
When II=1 cannot be met, SmartHLS's pipeline scheduling algorithm will try to find the smallest possible II
that satisfies the constraints and dependencies.

.. Comment out:
  .. NOTE::
   Luckily on the FPGA there are abundant block RAMs that can be used to store
   small arrays. By default SmartHLS assumes that each array is stored in a
   separate RAM. SmartHLS also assumes these are dual port RAMs allowing two read
   or writes every clock cycle.  Pointer aliasing can impact performance due to
   arrays being placed in global memory with limited ports. For more details
   see :ref:`codingstyle`.
   In this case, modulo scheduling will be required because standard scheduling
   has no concept of an initiation interval. Standard scheduling assumes that
   operations from separate control steps do not execute in parallel when
   satisfying resource constraints, which is no longer true in a loop pipeline.
   For instance, the standard approach may schedule the first memory operation
   in the first time step and the second memory operation in the third time
   step, but if new data is entering the pipeline every two cycles then these
   memory operations will occur in parallel and conflict with the single memory
   port.


.. Comment out:
   A Simple Loop Pipelining Example
    ~~~~~~~~~~~~~~~~~~~~~~

    We will use a simple example to demonstrate loop pipelining.
    First import the provided example project, ``loop_pipelining_simple``, contained within the SmartHLS installation directory (please
    refer to :ref:`import_user_guide_examples` for importing this example project into
    the SmartHLS IDE).
    Let's first run the C program in software by clicking the ``Compile Software``
    and ``Run Software`` buttons.

    .. code-block:: c

    #include <stdio.h>

    #define N 4
    // For the purpose of this example, we mark input arrays as volatile to 
    // prevent optimization based on input values. In a real program, the volatile keyword 
    // should only be used when absolutely necessary, as it prevents many optimizations.
    volatile int a[N] = {1, 2, 3, 4};
    volatile int b[N] = {5, 6, 7, 8};
    int c[N] = {0};

    // Simple loop with an array
    int main() {
        int i = 0, sum = 0;

    // The loop label is used for setting the pipelining constraint.
    my_loop_label:
    #pragma unroll 1 // Prevents the loop below from being unrolled.
        for (i = 0; i < N; i++) {
            printf("Loop body\n");
            printf("a[%d] = %d\n", i, a[i]);
            printf("b[%d] = %d\n", i, b[i]);
            c[i] = a[i] * b[i];
            printf("c[%d] = %d\n", i, c[i]);
            sum += c[i];
        }

        if (sum == 5 + 12 + 21 + 32)
            printf("PASS\n");
        else
            printf("FAIL\n");

        return sum;
    }

    .. NOTE::
      SmartHLS automatically unrolls loops with small trip counts. However, for a loop to be pipelined,
      it cannot be unrolled. Hence, for this example, we have added "``#pragma unroll 1``" to prevent
      the loop from being unrolled.

    When the program is executed, you can see in the console window that the array elements of ``a``, ``b``, and ``c`` are printed in order.
    Now click ``Compile Software to Hardware`` and ``Simulate Hardware``.
    You can see that the simulation output matches with the output from software execution, and the reported
    cycle latency is 24.
    Note that we have not yet pipelined the loop and it is still executed in sequential order.

    To pipeline the loop, open up the ``HLS Constraints`` window and add the ``Pipeline loop`` constraint with the value set to
    the loop label, "my_loop_label".
    Re-run ``Compile Software to Hardware`` and you should see that SmartHLS reports "Pipeline
    Initiation Interval (II) = 1".
    When you click on ``Simulate Hardware``, you should see that the cycle latency is now reduced to 12
    clock cycles, and the arrays are no longer accessed in order.
    For instance ``a[1]`` is printed out before ``c[0]``.
    This is because the second iteration (that prints ``a[1]``) now runs in
    parallel with the first iteration (that prints ``c[0]``).
    The second iteration's load operations for ``a[1]`` and ``b[1]`` are now
    happening at the same time as the first iteration's multiply that computes
    ``c[0]``.

    .. code-block:: none

    # Loop body
    # Loop body
    # a[          0] =           1
    # b[          0] =           5
    # Loop body
    # a[          1] =           2
    # b[          1] =           6
    # c[          0] =           5
    # Loop body
    # a[          2] =           3
    # b[          2] =           7
    # c[          1] =          12
    # a[          3] =           4
    # b[          3] =           8
    # c[          2] =          21
    # c[          3] =          32
    # PASS
    # At t=              290000 clk=1 finish=1 return_val=        70
    # Cycles:                   12

    To get more information about the schedule of the pipelined loop body, click
    ``Launch Schedule Viewer`` to open up SmartHLS's schedule viewer:

    .. image:: /images/open_scheduleviewer.png
        :scale: 60 %
        :align: center

    You will first see the call graph of the program --- the ``main`` function
    calling the ``printf`` function.
    Double-click the ``main`` function's circle to see the control-flow graph of the
    function. As shown below, you should find a circle named ``BB_1`` with a back edge
    (an arrow pointing to itself).  This means that the block is a loop
    body, and in this case it corresponds to the pipelined loop.

    .. image:: /images/loop_pipelining_simple_cfg.png
        :scale: 40 %
        :align: center

    Double-clicking on ``BB_1`` will take you to the ``Pipeline Viewer``, which
    illustrates the pipeline schedule:

    .. image:: /images/loop_pipelining_simple_pipeline_viewer.png
        :align: center

    The top two rows show the time steps (in terms of clock cycles) and the number of pipeline stages.
    For instance, the loop in the example has 5 pipeline stages and each
    iteration takes 5 cycles to complete.
    Each cell in the table shows all operations that are scheduled for each time step of a loop iteration.
    When looking at table horizontally, it shows all operations that are to occur (over the span of 5 clock cycles) for each loop iteration.
    When looking at table vertically, it shows all concurrent operations for each time step.
    For example, the first iteration's multiply operation (``%10 = mul nsw i32 %9,
    %8`` [#]_, shown in Cycle 1 column of Iteration: 0 row) is scheduled in cycle 1.  Meanwhile, also in cycle 1, the second
    iteration's load operations are also scheduled.  In cycle 4 (circled by a bold
    box), the pipeline reaches steady-state. This is when pipelined hardware reaches maximum utilization and is concurrently executing 5 loop iterations
    (since the loop is divided into 5 time steps, the pipelined hardware can execute 5 different loop iterations at the same time).

    .. [#] Use mouse to hover over the cell to see the complete statement of an operation.


.. _pthreads_multithreading:

Multi-threading with SmartHLS Threads 
----------------------------------------

In an FPGA hardware system, the same module can be instantiated multiple times to exploit spatial parallelism, where all module instances execute in parallel to achieve higher throughput.
SmartHLS allows easily inferring such parallelism with the use of SmartHLS Threads which is a simplified API of ``std::thread`` commonly used in software.
Parallelism described in software with SmartHLS threads is automatically compiled to parallel hardware with SmartHLS.
Each thread in software becomes an independent module that concurrently executes in hardware.

For example, the code snippet below creates ``N`` threads running the ``Foo`` function in software.
SmartHLS will correspondingly create ``N`` hardware instances all implementing the ``Foo`` function, and parallelize their executions.
SmartHLS also supports mutex and barrier APIs so that synchronization between threads can be specified using locks and barriers.

.. code-block:: c

    void Foo (int* arg);

    for (i = 0; i < N; i++) {
        thread[i] = hls::thread<void>(Foo, &args[i]);
    }

.. To see a complete multi-threading example, please refer to the example project,
    ``multi_threading_simple``, contained within the SmartHLS installation directory (see :ref:`import_user_guide_examples`
    for importing this example project into the SmartHLS IDE).
    The example also demonstrates the use of a mutex lock to protect a critical
    region.

SmartHLS supports ``hls::thread`` APIs, which are listed below in
:ref:`supported_parallel_apis`.

Note that for a ``hls::thread`` kernel, SmartHLS will automatically inline any of its descendant functions.
The inlining cannot be overridden with the ``noinline`` pragma (see :ref:`pragmas`).  

.. Comment out:
    Loop Multi-threading with OpenMP
    ----------------

    SmartHLS also supports the use of OpenMP,
    which allows parallelizing loops in a multi-threaded fashion (as opposed to
    loop pipelining which parallelizes loop iterations in a pipelined fashion).
    OpenMP provides a simple and a high-level approach for parallelization. With a
    single pragma, a user is able to parallelize loops without performing complicated code
    changes.
    For example, in the code snippet below, the loop performs a dot product of two
    arrays, ``A_array`` and ``B_array``.  To parallelize this loop using OpenMP,
    one simply puts an OpenMP pragma before the loop.

    .. code-block:: c

    #pragma omp parallel for num_threads(2) private(i)
    for (i = 0; i < SIZE; i++) {
        output[i] = A_array[i] * B_array[i];
    }

    The OpenMP pragma, ``#pragma omp parallel for``, is used to parallelize a ``for`` loop.
    The pragma uses a number of clauses. The ``num_threads`` clause sets the number
    of threads to use in the parallel execution of the ``for`` loop.
    The ``private`` clause declares the variables in its list to be private to each thread.
    In the above example, two threads will execute the loop in parallel, with one
    thread handling the first half of the arrays, and the other handling the second
    half of the arrays.
    SmartHLS will synthesize the two parallel threads into two concurrently running
    accelerators, each working on half of the arrays.
    Note that the parallel pragma in OpenMP is blocking – all threads executing the
    parallel section need to finish before the program execution continues.

    To see a complete OpenMP example, please refer to the example project,
    ``openmp_reduction``, contained within the SmartHLS installation directory (see :ref:`import_user_guide_examples`
    for importing this example project into the SmartHLS IDE).
    In this example, you will see how one can simply use OpenMP's ``reduction`` clause to sum up all
    elements in an array with parallel threads.
    
    SmartHLS supports a subset of OpenMP that is used for parallelizing loops.
    The supported OpenMP pragmas and OpenMP functions are listed in
    :ref:`supported_parallel_apis`.

.. _supported_parallel_apis:

Supported SmartHLS Thread APIs
--------------------------------

You can use SmartHLS thread library by including the header file:

.. code-block:: c

		#include "hls/thread.hpp"

The thread library is provided as a C++ template class.
The template argument of ``hls::thread<T>`` object specifies the return type ``T`` of the threaded function.
For example, ``hls::thread<int>`` is a thread that can invoke a function with ``int`` return type,
and ``hls::thread<void>`` is a thread that can invoke a function that returns ``void``.

To start the parallel execution of a function, we will pass the function and
function call arguments to the constructor of a new thread instance,

.. code-block:: c

  // f1 is a function that we would like to execute concurrently.
  void f1(int a);

  // Create a new thread 't1' with the function 'f1' and argument 'm'.
  // - <void> corresponds to the return type of 'f1'.
  // - Argument 'm' corresponds to the parameter 'a' of 'f1'.
  // - In software, this line creates a parallel thread to run the f1 function.
  // - In hardware, this line means a dedicated hardware module for f1 should
  // be created for this specific thread call, and the dedicated hardware
  // module will start the execution right here.
  hls::thread<void> t1(f1, m);


  // Another way to create a parallel thread:
  int f2();                     // f2 has no argument and the return type is <int>.
  hls::thread<int> t2;        // Create a thread 't2' instance first.
  t2 = hls::thread<int>(f2);  // Assign 't2' later with the function and arguments.


The code below shows how to join a thread (i.e., wait for the thread
completion), and optionally retrieve a non-void return value.
Note that joining a thread will block the execution until the threaded function finishes.

.. code-block:: c

  hls::thread<void> t1(f1, m);
  t1.join();  // The program will block here until thread 't1' finishes running 'f1'.

  hls::thread<int> t2 = hls::thread<int>(f2);
  int ret = t2.join();  // The program will wait for t2 to finish and retrieve the return value.

If you have used ``std::thread``, you may know passing an argument by reference requires a ``std::ref`` wrapper around the argument.
Similarly, ``hls::ref`` is used to wrap the passed-in by reference argument when the ``hls::thread`` is created:

.. code-block:: c

  int f(int &a);

  int x;
  hls::thread<int> t = hls::thread<int>(f, hls::ref(x));


.. NOTE::
  SmartHLS threads differs from ``std::thread`` in a few aspects:

  - SmartHLS threads support retrieving the return value from the threaded function (this functionality is only supported using ``std::future`` in the standard threading library).

  - SmartHLS threads use templates to specify the return type of the threaded function.

  - SmartHLS threads are auto-detaching, which means if the function where the thread is created is exited without using ``join``, the thread will be detached when destructed.
    But the threaded function can continue executing.

SmartHLS thread library also supports ``mutex`` and ``barrier`` as synchronization primitives. 

``mutex`` can be used to protect shared data from being simultaneously accessed by multiple threads.
``hls::mutex`` has ``lock()`` and ``unlock()`` methods.

``barrier`` provides a thread-coordination mechanism that allows at most an expected number of threads to block until the expected number of threads arrive at the barrier.
``hls::barrier`` has ``init()`` and ``wait()`` methods. 

The following example illustrates the use of ``hls::mutex`` and ``hls::barrier``:

.. literalinclude:: ../examples/user_guide_examples/threads_api/threads_api.cpp
	:language: cpp

.. _data_flow_parallelism_with_pthreads:

Data Flow Parallelism with SmartHLS Threads
------------------------------------------------

Data flow parallelism is another commonly used technique to improve hardware throughput, where a succession of computational tasks that process 
continuous streams of data can execute in parallel.
The concurrent execution of computational tasks can also be accurately described in software using ``hls::thread`` APIs.
In addition, the continuous streams of data flowing through the tasks can be inferred using SmartHLS's built-in FIFO data structure (see :ref:`streaming_lib`).

Let's take a look at the code snippet below, which is from the example project, "Fir Filter (Loop Pipelining with ``hls::thread``)", included in the SmartHLS IDE.
In the example, the ``main`` function contains the following code snippet:

.. code-block:: c

    // Create input and output FIFOs
    hls::FIFO<int> input_fifo(/*depth*/ 2);
    hls::FIFO<int> output_fifo(/*depth*/ 2);

    // Launch thread kernels.
    hls::thread<void> thread_var_fir(FIRFilterStreaming, &input_fifo, &output_fifo);
    hls::thread<void> thread_var_injector(test_input_injector, &input_fifo);
    hls::thread<void> thread_var_checker(test_output_checker, &output_fifo);

    // Join threads.
    thread_var_injector.join()
    thread_var_checker.join();

The corresponding hardware is illustrated in the figure below.

.. figure:: /images/FIR_Pthreads_schematic.*
	:align: center

The two hls::FIFO<int>s in the C++ code corresponds to the creation of the two FIFOs, where the bit-width is set according to the type shown in the constructor argument <int>.
The three ``hls::thread<void>`` calls initiate and parallelize the executions of three computational tasks, where each task is passed in a FIFO (or a pointer to a struct containing more than one FIFO pointers) as its argument.

The FIFO connections and data flow directions are implied by the uses of FIFO ``read()`` and ``write()`` APIs.
For example, the ``test_input_injector`` function has a ``write()`` call writing data into the ``input_fifo``, and the ``FIRFilterStreaming`` function uses a ``read()`` call to read data out from the ``input_fifo``.
This means that the data flows through the ``input_fifo`` from ``test_input_injector`` to ``FIRFilterStreaming``.

The ``join()`` API is called to wait for the completion of ``test_input_injector`` and ``test_output_checker``.
We do not "join" the ``FIRFilterStreaming`` thread since it contains an
infinite loop (see code below) that is always active and processes incoming
data from ``input_fifo`` whenever the FIFO is not empty.
This closely matches the *always running* behaviour of streaming hardware, where hardware is constantly running and processing data..

Now let's take a look at the implementation of the main computational task (i.e., the ``FIRFilterStreaming`` threading function).

.. code-block:: c

   void FIRFilterStreaming(hls::FIFO<int> *input_fifo,
                           hls::FIFO<int> *output_fifo) {
       // This loop is pipelined and will be "always running", just like how a
       // streaming module always runs when new input is available.
       #pragma HLS loop pipeline
       while (1) {
           // Read from input FIFO.
           int in = input_fifo->read();

           printf("FIRFilterStreaming input: %d - %d\n", i, in);
           static int previous[TAPS] = {0}; // Need to store the last TAPS -1 samples.
           const int coefficients[TAPS] = {0, 1, 2,  3,  4,  5,  6,  7,
                                           8, 9, 10, 11, 12, 13, 14, 15};

           int j = 0, temp = 0;

           for (j = (TAPS - 1); j >= 1; j -= 1)
               previous[j] = previous[j - 1];
           previous[0] = in;

           for (j = 0; j < TAPS; j++)
               temp += previous[TAPS - j - 1] * coefficients[j];

           int output = (previous[TAPS - 1] == 0) ? 0 : temp;

           // Write to output FIFO.
           output_fifo->write(output);
      }
  }

In the code shown in the example project, you will notice that all three threading functions contain a loop, which repeatedly reads and/or writes data from/to FIFOs to perform processing.
In SmartHLS, this is how one can specify that functions are continuously processing data streams that are flowing through FIFOs.

Further Throughput Enhancement with Loop Pipelining
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In this example, the throughput of the streaming circuit will be limited by how frequently the functions can start processing new data (i.e., how frequently the new loop iterations can be started).
For instance, if the slowest function among the three functions can only start a new loop iteration every 4 cycles, then the throughput of the entire streaming circuit will be limited to processing one piece of data every 4 cycles.
Therefore, as you may have guessed, we can further improve the circuit throughput by pipelining the loops in the three functions.
If you run SmartHLS synthesis for the example (``Compile Software to Hardware``), you should see in the ``Pipeline Result`` section of our report file, ``summary.hls.<top_level>.rpt``, that all loops can be pipelined with an initiation interval of 1.
That means all functions can start a new iteration every clock cycle, and hence the entire streaming circuit can process one piece of data every clock cycle.
Now run the simulation (``Simulate Hardware``) to confirm our expected throughput. The reported cycle latency should be just slightly more than the number of data samples to be processed
(``INPUTSIZE`` is set to 128; the extra cycles are spent on activating the parallel accelerators, flushing out the pipelines, and verifying the results).

.. _function_pipelining:

Function Pipelining
---------------------

You have just seen how an efficient streaming circuit can be described in software by using loop pipelining with SmartHLS threads.
An alternative way to describe such a streaming circuit is to use ``Function Pipelining``.
When a function is marked to be pipelined (by using the ``Pipeline Function`` constraint), SmartHLS will implement the function as a pipelined circuit that can start a new invocation every ``II`` cycles.
That is, the circuit can execute again while its previous invocation is still executing, allowing it to continuously process incoming data in a pipelined fashion.
This essentially has the same circuit behaviour as what was described in the previous example (loop pipelining with threads) in the :ref:`data_flow_parallelism_with_pthreads` section, without having to write the software code using threads.
This feature also allows multiple functions that are added to the ``Pipeline function`` constraint to execute in parallel, achieving the same hardware behaviour as the previous loop pipelining with threads example.

.. comment:
  To simplify the ``C`` code, SmartHLS provides a ``Function Pipelining`` feature as an alternative approach to describing streaming circuits.
  With this feature, we do not need to add a loop around the processing algorithm for specifying continuous execution, or use the thread APIs to initiate the concurrent execution among a succession of tasks.
  Instead, we just need to add a ``Pipeline Function`` constraint with the name of the function (:ref:`smarthls_constraints`).
  SmartHLS will then generate a pipelined circuit, which implements the function's algorithm and automatically starts a new invocation every ``II`` cycles.
  Meaning that the circuit can execute again while its previous invocation (of the function algorithm) is still executing.
  This feature also allows multiple funcstions that are added with ``Pipeline function`` constraint to execute in parallel.
..
  Notice the difference between generated hardware and software specification, the generated hardware automatically starts a new invocation to continuously processes the data streams, while the software function does not imply so but only specifies the processing algorithm.

When using this feature, the user-specified top-level function (see :ref:`custom_top_level`) can only call functions that are specified to be function pipelined (e.g., the top-level function cannot call one function pipeline and one non-function pipeline).  
The top-level function cannot have any control flow (i.e., loops, if/else statements), and cannot perform any operations other than declaring variables (i.e., memories, FIFOs) and calling function pipelines. 

For SW/HW co-simulation, the top-level function that calls one or more function pipelines can only have interfaces that are created from FIFOs and constant values (top-level interfaces are created from top-level function arguments and global variables that are accessed from both software testbench functions and hardware kernel functions). 

Please refer to the `C++ Canny Edge Detection (SW/HW Co-Simulation)` example included in the SmartHLS IDE for an example of using function pipelining. 

In this example, you should see the top-level function, ``canny``, as below.  

.. code-block:: c

    void canny(hls::FIFO<unsigned char> &input_fifo,
               hls::FIFO<unsigned char> &output_fifo) {
       #pragma HLS function top

       hls::FIFO<unsigned char> output_fifo_gf(/* depth = */ 2);
       hls::FIFO<unsigned short> output_fifo_sf(/* depth = */ 2);
       hls::FIFO<unsigned char> output_fifo_nm(/* depth = */ 2);

       gaussian_filter(input_fifo, output_fifo_gf);
       sobel_filter(output_fifo_gf, output_fifo_sf);
       nonmaximum_suppression(output_fifo_sf, output_fifo_nm);
       hysteresis_filter(output_fifo_nm, output_fifo);
    }

As shown above, the top-level function has been specified with ``#pragma HLS function top``. The top-level function calls four functions, ``gaussian_filter, sobel_filter, nonmaximum_suppression, and hysteresis_filter``, each of which are specified to be function pipelined (with ``#pragma HLS function pipeline``). 
The top-level arguments are ``input_fifo`` and ``output_fifo``. The ``input_fifo`` is given as an argument into the first function, ``gaussian_filter``, and gives the inputs into the overall circuit. 
The ``output_fifo`` is given as an argument into the last function, ``hysteresis_filter``, and receives the outputs of the overall circuit. 
There are also intermediate FIFOs, ``output_fifo_gf``, ``output_fifo_sf``, and ``output_fifo_nm``, which are given as arguments into the function pipelines and thus connect them (i.e., outputs of ``gaussian_filter`` is given as inputs to ``sobel_filter``). 

When synthesizing a top-level function with multiple pipelined sub-functions, SmartHLS will automatically parallelize the execution of all sub-functions that are called in the top-level function, forming a streaming circuit with data flow parallelism.
In this case ``gaussian_filter`` executes as soon as there is data in the ``input_fifo``, and ``sobel_filter`` starts running as soon as there is data in the ``output_fifo_sf``.
In other words, a function pipeline does not wait for its previous function pipeline to completely finish running before it starts to execute, but rather, it starts running as early as possible.
Each function pipeline also starts working on the next data while the previous data is being processed (in a pipelined fashion).
If the initiation interval (II) is 1, a function pipeline starts processing new data every clock cycle.
Once the function pipelines reach steady-state, all function pipelines execute concurrently.
This example showcases the synthesis of a streaming circuit that consists of a succession of concurrently executing pipelined functions. 

.. NOTE::
  In the generated Verilog for a function pipelined hardware, the ``start`` input port serves as an enable signal to the circuit.
  The circuit stops running when the ``start`` signal is de-asserted. To have the circuit running continuously, the ``start`` input port should be kept high.


.. _memory_partitioning:

Memory Partitioning
---------------------

Memory Partitioning is an optimization where aggregate types such as arrays and structs are partitioned into smaller pieces
allowing for a greater number of reads and writes (accesses) per cycle. SmartHLS instantiates a RAM for each aggregate
type where each RAM has up to two ports (allowing up to two reads/writes per cycle). Partitioning aggregate types into
smaller memories or into its individual elements allows for more accesses per cycle and improves memory bandwidth.

There are two flavors of memory partitioning, access-based partitioning and user-specified partitioning.

.. Note::

  * Accessing memory outside of an array dimension is not supported by memory partitioning and will sometimes cause
    incorrect circuit behavior. An example of this is casting a 2-d array to a pointer and iterating through the size
    of the 2-d array.

  * Pointers that alias to different memories (e.g. a function called with different memories) or different sections of the same memory (e.g. a pointer that is assigned to multiple memories based on a condition) can be partitioned if the aliased memories/sections have the same partitions. Otherwise, access-based partitioning will not partition the aliased memories, or a warning will be displayed for user-specified partitioning. The following example shows an unsupported aliasing case:

    .. code-block:: c

      int sum_array(int *z) {
      #pragma HLS function noinline
        int sum = 0;
        for (int i = 0; i < 100; i++)
          sum += z[i];
        return sum;
      }

      int main() {
      #pragma HLS function top
      #pragma HLS memory partition variable(x) type(block) dim(1) factor(2)
        int x[100];   // x should be partitioned into 2 partitions
      #pragma HLS memory partition variable(x) type(cyclic) dim(1) factor(4)
        int y[100];   // x should be partitioned into 4 partitions
        // ...
        int sum_x = sum_array(x);
        int sum_y = sum_array(y);
        // ...
      }

    SmartHLS will output a warning:

    .. code-block:: text

      Warning: The user specified memory "x" on line 80 of test.cpp could not be partitioned because the memory aliases with another memory at line 71 of test.cpp that has a different partitioning.
      Warning: The user specified memory "y" on line 82 of test.cpp could not be partitioned because the memory aliases with another memory at line 71 of test.cpp that has a different partitioning.

  * Partitions with no accesses are discarded.


.. * Pointers that alias to different memories or different sections of the same memory (e.g. a pointer that is assigned
  to multiple memories based on a condition) are not supported in memory
  partitioning. The aliased memories will not be partitioned. The exception
  to this is that functions that get called with different pointers are handled properly for user-specified
  partitioning.

.. * Comparisons and other non-arithmetic operators on pointers are not supported by memory partitioning and will prevent
     partitioning.

.. * Access-based partitioning will not create new accessing instructions and therefore can only modify existing ones.
     This limits partitions to be the same shape as the range of accesses, with overlapping ranges merged into the same
     partition. If the shape of the overlapping ranges cannot nicely map old indexes to new indexes using a linear relationship
     the memory is not partitioned. This makes it so that if there are multiple overlapping ranges, the partition may become
     large and or not be partitioned at all, reduce performance gain.


.. _access_based_partitioning:

Access-Based Memory Partitioning
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Access-based partitioning is automatically applied to all memories except for those at the top-level interfaces (:ref:`io_memory`).
This flavor of memory partitioning will analyze the ranges of all accesses to a memory and create partitions based on
these accesses. After analyzing all memory accesses, independent partitions will be implemented in independent memories. 
If two partitions overlap in what they access, they will be merged into one partition. If there are any sections of the memory that is not accessed, it will be discarded to reduce memory usage.
For example, if there are two loops, where one loop accesses the first half of an array and the second loop accesses the second half of the array, the accesses to the array from the two loops are completely independent.
In this case the array will be partitioned into two and be implemented in two memories, one that holds the first half of the array and another that holds the second half of the array.
However, if both loops access the entire array, their accesses overlap, hence the two partitions will be merged into one and the array will just be implemented in a single memory (without being partitioned).
Access-based partitioning is done automatically without needing any memory partition pragmas, in order to automatically improve memory bandwidth and reduce memory usage whenever possible.

.. An access range is the range of elements of structs and arrays a single accessing load/store instruction can access.
.. SmartHLS generates a memory partition for each access range, and if there are overlapping access ranges (e.g., one load instruction accesses some of the same elements as another load instruction),
.. the corresponding partitions will be merged.

**Example**

Access-based partitioning is automatically applied to all memories by SmartHLS except for interface memories (top-level function arguments and global variables accessed by both software testbench and hardware functions) to the
top-level function. Interface memories need to be partitioned with the memory partition pragma.
See the code snippet below that illustrate an example of accessed-based partitioning.

.. literalinclude:: ../examples/user_guide_examples/memory_partitioning/memory_part_access/memory_partitioning.cpp
	:language: cpp
	:lines: 6-7,15,22-25

In the example above, each iteration of the loop access an element of ``array`` and adds it to ``result``. The ``unroll`` pragma is applied to completely unroll the loop.
Without partitioning, SmartHLS will implement this array in a RAM (with 1000 elements), where an FPGA RAM can have up to two read/write ports.
In this case, the loop will take 500 cycles, as 1000 reads are needed from the RAM and up to two reads can be performed per cycle with a two ported memory.

With access-based partitioning, the accesses to the above array will be analyzed. With unrolling, there will be 1000
load instructions, each of which will access a single array element, with no overlaps in accesses between the load instructions (i.e., the accesses of each load instruction are independent).
This creates 1000 partitions, with one array element in each partition.
After partitioning, all 1000 reads can occur in the same clock cycle, as each memory will only need one memory access. Hence the entire loop can finish in a single cycle.
With this example, we can see that memory partitioning can help to improve memory bandwidth and improve performance.

With access-based partitioning, SmartHLS outputs messages to the console specifying which memory has been partitioned into how many partitions, as shown below:

.. literalinclude:: ../examples/user_guide_examples/memory_partitioning/memory_part_access/golden.hls.log
	:language: text
	:lines: 10

Please refer to the :ref:`optimizationguide` for more examples and details.

.. _user_specified_memory_partitioning:

User-Specified Memory Partitioning
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The user can explicitly specify a memory to be partitioned via the ``memory partition`` pragma (``#pragma HLS memory partition variable``, ``#pragma HLS memory partition argument``). See :ref:`pragma_memory_partition_argument` and :ref:`pragma_memory_partition_variable` for more details.
User-specified partitioning also analyzes accesses but partitions based on a predefined structure and array dimension.
SmartHLS supports ``block``, ``cyclic`` and ``complete`` types for arrays, and ``struct_fields`` and ``complete`` partitioning for ``struct``. Specifying the type to be ``none`` prevents partitioning the specified memory.

The memory partition pragma has optional arguments ``type`` and ``dim`` that specifies the partition type and dimension to partition, respectively.
The default type is ``complete`` which means to partition the array into individual elements, and the default dimension is ``0`` which means to partition all dimensions.
The ``factor`` argument is required for ``block`` and ``cyclic`` types to specify the partitioning factor, i.e. the number of partitions. Note that the pragma will be ignored if the ``factor <= 1``.

.. Note::

    Lower numbered dimensions correspond to left-ward dimensions of the array and higher numbered dimensions correspond to right-ward dimensions of the array. For an a 2d array ``A[N][M]``, ``dim(1)`` refers to the dimension with ``N`` elements, and ``dim(2)`` refers to the dimension with ``M`` elements.

With user-specified partitioning, SmartHLS outputs messages to the console stating the variable set to be partitioned and its settings.
SmartHLS also outputs messages specifying if a memory has been partitioned and into how many partitions.
If a memory is specified to be partitioned but cannot be partitioned, SmartHLS will output a warning.

.. code-block:: text

    Info: Found user-specified memory: "array" on line 6 of test.c, with partition type: Complete, partition dimension: 0.
    Info: Found user-specified memory: "array3d" on line 27 of test.c, with partition type: Block, partition dimension: 1, partition factor 2.
    Warning: The user-specified memory "array3d" on line 27 of test.c could not be partitioned because a loop variable indexing into a multi-dimenional array comes from a loop variable and goes out of the array dimension bounds. Going outside of array dimension bounds is not supported for memory partitioning.
    Info: Partitioning memory: array into 8 partitions.

.. The ability of user-specified partitioning to partition regardless of access patterns makes it ideal to use on bottleneck
   memories where many accesses need to performed on them every cycle.

Please refer to the :ref:`optimizationguide` for more examples and details.

.. _block_memory_partitioning:

Block Partitioning
+++++++++++++++++++++++

Block partitioning aggregates consecutive elements of the original array into partitions. The number of partitions (blocks) is defined by the ``factor`` argument.

.. code-block:: c

    #pragma HLS memory partition variable(array2d) type(block) dim(1) factor(2)
    int array2d[10][20];

For example, in the above code snippet ``array2d`` is specified to partition dimension ``1`` with factor ``2``. The result is two ``int[5][20]`` partitions where the first partitions has elements ``0, 1, 2, 3, 4``, and the second has elements ``5, 6, 7, 8, 9`` of dimension ``1``.

.. Note::

  If the number of elements ``N`` in the specified dimension is not divisible by ``factor``, all the partitions will have the same size ``B = ceil(N/factor)``, except the last partition which will have the remaining elements ``N - (factor - 1) * B``. For example, if ``N = 10`` and ``factor = 3``, the resulting partitions will have ``4``, ``4`` and ``2`` elements respectively.


.. _cyclic_memory_partitioning:

Cyclic Partitioning
+++++++++++++++++++++++

Cyclic partitioning interleaves elements from the original array into partitions. The number of interleaved partitions is defined by the ``factor`` argument.
The array is partitioned cyclically by arbitrating the elements between the partitions, putting one element into each partition before coming back to the first one until the array is fully partitioned.

.. code-block:: c

    #pragma HLS memory partition variable(array2d) type(block) dim(2) factor(2)
    int array2d[10][10];

For example, in the above code snippet ``array2d`` is specified to partition dimension ``2`` with factor ``2``. The result is two ``int[10][5]`` partitions where the first partition has elements ``0, 2, 4, 6, 8``, and the second has elements ``1, 3, 5, 7, 9`` of dimension ``2``.

.. Note::

  If the number of elements ``N`` in the specified dimension is not divisible by ``factor``, the number of complete partitions with ``B = ceil(N/factor)`` elements will be ``M = N % factor``, and the rest of partitions will have ``B-1`` elements. For example, if ``N = 10`` and ``factor = 3``, the resulting partitions will have ``4``, ``3`` and ``3`` elements respectively.


.. _complete_memory_partitioning:

Complete Partitioning
+++++++++++++++++++++++

Complete partitioning deconstructs the array into individual elements along the specified dimension. For a multi-dimensional array, each element of the specified dimension will correspond to a partition with the rest of the dimensions preserved. For a one-dimensional array, individual elements are mapped to registers. If ``dim(0)`` is specified, complete partitioning is applied across all dimensions resulting in scalar elements.

.. Note::

  Applying complete partitioning on a (array of) struct, partitions all struct fields (including nested struct elements) and array dimensions.

**Example**

.. literalinclude:: ../examples/user_guide_examples/memory_partitioning/memory_part_user/memory_partitioning.cpp
	:language: cpp
	:lines: 6-9,19-21

The example above shows the same example that was shown for access-based partitioning, however, the loop is not unrolled in this case.
Access-based partitioning will try to partition the array but will only find one load instruction in the loop that accesses the entire array.
This preventing access-based partitioning as all eight accesses come from the same load instruction.

User-specified partitioning can be used to force partitioning of this array with a predefined structure. In the example above,
the memory partition pragma specifies the array to be partitioned completely into eight individual elements.

.. literalinclude:: ../examples/user_guide_examples/memory_partitioning/memory_part_user/golden.hls.log
        :language: text
        :lines: 11

The benefit in this case is that the loop does not have to be unrolled, which can be useful in cases like when the loop is
pipelined and cannot be unrolled (see :ref:`loop_pipelining`).


.. _struct_fields_memory_partitioning:

Struct-Fields Partitioning
++++++++++++++++++++++++++++++++++++

Struct-fields partitioning partitions a (array of) struct argument / variable into its individual fields such that each field is a partition.
Unlike complete partitioning, if a field in the partitioned struct is an aggregate type (struct or array), the field is not further partitioned to its elements.
Note that applying Struct-fields partitioning to  an array-of-struct creates an array for each field in the struct.
Unaccessed partitions (fields) are discarded, but the unaccessed elements in an aggreagte partition (field) are not discarded.

**Example**

.. literalinclude:: ../examples/user_guide_examples/struct_sum/struct_sum.cpp
	:language: cpp
	:lines: 3-12,15-23

The example above shows ``array``, an array of struct of type `Ty`, is
partitioned using Struct-fields partitioning.
With the user-specified partitioning, SmartHLS outputs messages to the console stating that the argument
set to be partitioned and how many partitions are created.
The three partitions are ``array.x[8]``, ``array.y[8][2]``, and ``array.z[8]``, where the 8-element dimensions are inherited from the original array size.

.. literalinclude:: ../examples/user_guide_examples/struct_sum/golden.hls.log
	:language: text
	:lines: 10,11

The summary report from SmartHLS lists the 3 partitions created from the fields of the struct.
Note that the array field `Ty.y` has one partition, and similarly the struct field `Ty.z`.

.. literalinclude:: ../examples/user_guide_examples/struct_sum/golden.summary.hls.sum.rpt
	:language: text
	:lines: 103-111

.. include:: struct_support.inc

SmartHLS C/C++ Library
------------------------

SmartHLS includes a number of C/C++ libraries that allow creation of efficient hardware.

.. _streaming_lib:

Streaming Library
~~~~~~~~~~~~~~~~~~

The streaming library includes the FIFO (first-in first-out) data structure along with its associated API functions.
The library can be compiled in software to run on the host machine (e.g., x86).
Each FIFO instance in software is implemented as a First Word Fall Through (FWFT) FIFO in hardware.

The FIFO library is provided as a C++ template class.
The FIFO data type can be flexibly defined and specified as a template argument of the FIFO object.
For example, the FIFO data type could be defined as a struct containing multiple integers:

.. code-block:: c

		struct AxisWord { ap_uint<64> data; ap_uint<8> keep; ap_uint<1> last; };

		hls::FIFO<AxisWord> my_axi_stream_interface_fifo;

.. NOTE::

  A valid data type could be any of the
  1) C/C++ primitive integer types,
  2) SmartHLS's :ref:`ap_lib` (ap_int, ap_uint, ap_fixpt, ap_ufixpt),
  or 3) a struct containing primitive integer types or SmartHLS's C++ arbitrary
  Precision Data Types.
  In the case of a struct type, it is prohibited to use 'ready' or 'valid' as
  the name of a struct field.  This is because in the generated Verilog, a FIFO
  object will introduce an AXI-stream interface associated with valid/ready
  handshaking signals and the names will overlap.

You can use the C++ streaming library by including the header file:

.. code-block:: c

		#include "hls/streaming.hpp"

.. NOTE::
  Users should always use the APIs below to create and access FIFOs. Any other uses of FIFOs are not supported in SmartHLS.

===================================================  =======================================================================================
Class Method                                         Description                                                                            
===================================================  =======================================================================================
``FIFO<T> ()``                                       Create a new FIFO.                                                                     
``FIFO<T> (unsigned depth)``                         Create a new FIFO with the specified depth.                                           
``void write(T data)``                               Write ``data`` to the FIFO.                                                           
``T read()``                                         Read an element from the FIFO.                                                         
``bool empty()``                                     Returns 1 if the FIFO is empty.                                                       
``bool full()``                                      Returns 1 if the FIFO is full.                                                        
``void setDepth(unsigned depth)``                    Set the FIFO's depth.                                                                  
===================================================  =======================================================================================

.. ``unsigned get_usedw()``                          .. ``Returns the number of elements in the FIFO``

An example code for using the streaming library is shown below.

.. literalinclude:: ../examples/user_guide_examples/fifo/fifo.cpp
	:language: cpp

As shown above, there are two ways of creating a FIFO (``hls::FIFO<unsigned> my_fifo`` and ``hls::FIFO<unsigned> my_fifo_depth_10(10)``).
The width of the FIFO is determined based on the templated data type of the FIFO. 
For example, ``FIFO<unsigned> my_fifo`` creates a FIFO that is 32 bits wide.
The FIFO's data type can be any primitive type or arbitrary bitwidth types (ap_int/ap_uint/ap_fixpt/ap_ufixpt), 
or a struct of primitive/arbitrary bitwidth types (or nested structs of those types) but 
cannot be a pointer or an array (or a struct with a pointer/array). 
An array or a struct of FIFOs is supported. 

The depth of the FIFO can be provided by the user as a constructor argument
when the FIFO is declared, or it can also be set afterwards with the ``setDepth(unsigned depth)`` function. 
If the depth is not provided by the user, SmartHLS uses a default FIFO depth of 2. 
The depth of a FIFO can also be set to 0, in which case SmartHLS will create direct ready/valid/data wire connections (without a FIFO) between the source and the sink. 

.. FIFOs are typically implemented with block RAMs on an FPGA, where block RAMs are important resources for an FPGA design. 
.. Hence, user may want to explicitly specify which type of FPGA resource is to be used for implementing a FIFO. 
.. Specifying the implementation type of a FIFO is only currently supported when targetting a Xilinx device, 
.. which can be done by specifying the type as a constructor argument (``FIFO<unsigned> my_fifo(10, hls::LUTRAM``),
.. or by using the setType function (``my_fifo.setType(hls::LUTRAM)``).
.. The following FIFO implementation types are supported.
.. 
.. ===================     ===================================
.. Implementation Type     Description                                                                         
.. ===================     ===================================
.. ``hls::REG``            Implement the FIFO with registers.
.. ``hls::LUTRAM``         Implement the FIFO with LUTRAMs.
.. ``hls::URAM``           Implement the FIFO with Ultra RAMs.
.. ``hls::RAM``            Implement the FIFO with block RAMs.
.. ===================     ===================================
.. 
.. If the implementation type is not specified by the user when targetting a Xilinx device, SmartHLS will automatically determine the implmentation type based on the depth of the FIFO. 
.. For non-Xilinx devices, we implement a generic FIFO module in Verilog and allow the vendor synthesis tool to decide which FPGA resource to use. 


Streaming Library - Blocking Behaviour
++++++++++++++++++++++++++++++++++++++++++++++++++


Note that the fifo ``read()`` and ``write()`` calls are blocking. 
Hence if a module attempts to read from a FIFO that is empty, it will be stalled. 
Similarly, if it attempts to write to a FIFO that is full, it will be stalled. 
If you want non-blocking behaviour, you can check if the FIFO is 
empty (with ``empty()``) before calling ``read()``, and likewise, check
if the FIFO is full (with ``full()``) before calling ``write()`` (see :ref:`streaming_lib_non_blocking`).

With the blocking behaviour, if the depths of FIFOs are not sized properly, 
it can cause a deadlock. SmartHLS prints out messages to alert the user that
a FIFO is causing stalls. 

In hardware simulation, the following messages are shown. 

.. code-block:: bash
    
    Warning: fifo_write() has been stalled for     1000000 cycles due to FIFO being full.
    Warning: fifo_read() has been stalled for     1000000 cycles due to FIFO being empty.
    Warning: fifo_read() has been stalled for     1000000 cycles due to FIFO being empty.
    Warning: fifo_write() has been stalled for     1000000 cycles due to FIFO being full.
    Warning: fifo_read() has been stalled for     1000000 cycles due to FIFO being empty.
    Warning: fifo_read() has been stalled for     1000000 cycles due to FIFO being empty.

If you continue to see these messages, you can suspect that there may be a
deadlock. In this case, we recommend making sure there is no blocking read from
an empty FIFO or blocking write to a full FIFO, and potentially increasing the
depth of the FIFOs.

.. NOTE::
    We recommend the minimum depth of a FIFO to be 2, as a depth of 1 FIFO can cause excessive stalls.

.. _streaming_lib_non_blocking:

Streaming Library - Non-Blocking Behaviour
++++++++++++++++++++++++++++++++++++++++++++++++++

As mentioned above, non-blocking FIFO behaviour can be created with the use of ``empty()`` and ``full()`` functions. 
Non-blocking FIFO read and write can be achieved as shown below. 

.. code-block:: bash
    
    if (!fifo_a.empty())
        unsigned data_in = fifo_a.read();

    if (!fifo_b.full())
        fifo_b.write(data_out);

.. NOTE::
    A deadlock may occur if a fifo with a depth of 0 uses non-blocking write on its source and non-block read on its sink. 


.. comment:
    .. _arbitrary_bitwidth:

    C Arbitrary Bit-width Data Type Library
    ~~~~~~~~~~~~~~~~~~~~~~

    For efficient hardware generation, SmartHLS allows specifying data types of any bit-widths from 1 to 64.
    You can use SmartHLS\'s arbitrary bit-width data type library by including the following header file:

    .. code-block:: c

		#include "hls/types.h"

    This library defines data types for unsigned integers from 1 bit (``uint1``) to 64 bits (``uint64``),
    as well as for signed integers from 1 bit (``int1``) to 64 bits (``int64``).

    In software, standard data types (i.e., char, int, long long) are used even though
    their entire bit-widths are not required in many cases.
    Hardware implemented on an FPGA operates at the bit-level, hence a circuit can be
    optimized to the exact bit-width that is required.
    Using arbitrary bit-width data types provides information to SmartHLS which
    is used to produce hardware with the exact specified bit-widths.
    This can help to reduce circuit area.

    An example using arbitrary bit-width data types are shown below:

    .. code-block:: c

  #include "hls/types.h"
  #include <stdio.h>
  #define SIZE 8

  // marked as volatile, as for a simple program such as this,
  // SmartHLS optimizes away the arrays with constant propagation
  volatile uint3 a[SIZE] = {0, 1, 2, 3, 4, 5, 6, 7};
  volatile uint4 b[SIZE] = {8, 9, 10, 11, 12, 13, 14, 15};

  int main() {
    volatile uint7 result = 0;
    volatile uint4 i;

    #pragma unroll 1
    for (i=0; i<SIZE; i++) {
        result += a[i] + b[i];
    }

    printf("result = %d\n", result);
  }

    In the example, we have reduced all variables and arrays to their minimum bit-widths.
    This is translated to reduced widths in hardware.
    When SmartHLS runs, it prints out the following to inform the user that it has detected
    the use of arbitrary bit-width data types:

    .. NOTE::

  We have used the volatile keyword to prevent the variables from being optimized
  away for the purpose of this example. We do not recommend using this keyword
  unless absolutely necessary, as it can lead to higher runtime and area. 

    .. code-block:: text

  Info: Setting the width of memory 'a' to the user-specified custom width of 
        3 bit(s)
  Info: Setting the width of memory 'b' to the user-specified custom width of 
        4 bit(s)
  Info: Setting the width of memory 'main_0_result' to the user-specified custom 
        width of 7 bit(s)
  Info: Setting the width of memory 'main_0_i' to the user-specified custom 
        width of 4 bit(s)

    .. NOTE::

  Note that in an actual program (where the volatile keyword is not used), 
  some variables may not show up in the SmartHLS printout. 
  This occurs when SmartHLS optimizes the program so that the variables are no 
  longer required. 
   
.. _ap_lib:

C++ Arbitrary Precision Data Types Library
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The C++ Arbitrary Precision Data Types Library provides numeric types ``ap_[u]int`` and ``ap_[u]fixpt``, which can be used to specify data types of arbitrary bitwidths in software (e.g., ap_int<9> for a 9-bit integer variable).
These data types will be efficiently translated to create hardware with the exact widths. The data types also come with bit manipulation utilities, such as bit range selection and concatenation.

.. _ap_int:

C++ Arbitrary Precision Integer Library
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The C++ ``ap_[u]int`` type allows specifying signed and unsigned data types of any bitwidth. 
They can be used for arithmetic, concatenation, and bit level operations. You can use the ``ap_[u]int`` type
by including the following header file.

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
	:language: cpp
	:lines: 2

The desired width of the ``ap_[u]int`` can be specified as a template parameter, ``ap_[u]int<W>``,
allowing for wider types than the existing C arbitrary bit-width library.

An example using the C++ library is shown below.

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
        :language: cpp
        :lines: 2,3,6,138-157,160

In the above code we iterate through a 128 bit unsigned integer in four bit segments, 
and track the difference between how many segments are above and below 7. 
All variables have been reduced to their specified minimum widths.

Printing Arbitrary Precision integers
++++++++++++++++++++++++++++++++++++++++++++
The C++ Arbitrary Precision Integer Library provides some utilities for printing ``ap_[u]int`` types. The ``to_string(base, signedness)`` function
takes an optional base argument (one of 2, 10, and 16) which defaults to 16, as well as an optional signedness argument which determines if the data
should be printed as signed or unsigned, which defaults to false. The output stream operator ``<<`` is also overloaded to put arbitrary precision integer
types in the output stream as if they were called with the default ``to_string`` arguments.

Some example code using these utilities is shown below.

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
        :language: cpp
        :lines: 2-6,10-25

Initializing Arbitrary Precision integers
++++++++++++++++++++++++++++++++++++++++++++

The ``ap_[u]int`` types can be constructed and assigned to from other arbitrary precision integers, C++ integral
types, ``ap_[u]fixpt`` types, as well as concatenations and bit selections. They can also be initialized from a hexadecimal
string describing the exact bits.

Some examples of initializing arbitrary precision integer types are show below.

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
        :language: cpp
        :lines: 1-6,26-57

C++ Arbitrary Precision Integer Arithmetic
++++++++++++++++++++++++++++++++++++++++++++
The C++ Arbitrary Precision Integer library supports all standard arithmetic, logical bitwise, shifts, and comparison operations. 
Note that for shifting that >> and << are logical, and the .ashr(x) function implements arithmetic right shift.
The output types of an operation are wider than their operands as necessary to hold the result. Operands of ap_int, and ap_uint type, 
as well as operands of different widths can be mixed freely. 
By default ap_int will be sign extended to the appropriate width for an operation, 
while ap_uint will be zero extended. When mixing ap_int and ap_uint in an arithmetic operation 
the resulting type will always be ap_int. Some of this behaviour is demonstrated in the example below.

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
        :language: cpp
        :lines: 1-6,58-82

C++ Arbitrary Precision Integer Explicit Conversions
++++++++++++++++++++++++++++++++++++++++++++++++++++++
The ``ap_[u]int`` types support several explicit conversion functions which allow the value to be interpreted in different ways.
The ``to_uint64()`` function will return a 64 bit ``unsigned long long`` with the same bits as the original ``ap_[u]int``, zero extending
and wrapping as necessary. Assigning an ``ap_[u]int`` wider than 64 bits to an ``unsigned long long`` would also wrap to match widths,
without needing to call ``to_uint64()``. The ``to_int64()`` function will return a 64 bit ``signed long long`` and will sign extend as necessary. 

An arbitrary precision integer data type can be casted to an arbitrary precision fixed-point data type with the ``to_fixpt<I_W>()`` and ``to_ufixpt<I_W>()`` functions (returns ``ap_fixpt<W, I_W>`` and ``ap_ufixpt<W, I_W>`` types respectively), with the same bits as the original ``ap_[u]int<W>``. 
For more on the ``ap_[u]fixpt`` template, please refer to the :ref:`ap_fixpt` section.

An example demonstrating these functions is shown below.

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
        :language: cpp
        :lines: 2-6,83-106

C++ Arbitrary Precision Bit-level Operations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The C++ Arbitrary Precision Library provides utilities to select, and update ranges of arbitrary precision data, 
as well as perform concatenation.

Bit selection and updating is defined for all C++ arbitrary precision numeric types. Concatenation is defined on all 
C++ Arbitrary Precision Library constructs including arbitrary precision numeric types, as well as bit selections, and other concatenations. 

Selecting and Assigning to a Range of Bits
++++++++++++++++++++++++++++++++++++++++++++

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
        :language: cpp
        :lines: 2-6,107-123

On C++ arbitrary precision types ``num(a, b)`` (or ``num.range(a, b)``) will select and create a reference to the underlying arbitrary precision value.
The operator ``num[a]`` selects and creates a reference to a single bit.
This reference can be assigned to, and used to access the underlying data.
The arbitrary precision ``num.byte(n, s = 8)`` function selects and creates a
reference to the ``n-th`` byte of the number which can be assigned to and used
to access the underlying data. The second argument to the ``byte`` function is
an optional argument which defines the number of bits per byte, and defaults to 
8.

Bit Concatenation
++++++++++++++++++++++++

.. literalinclude:: ../examples/user_guide_examples/int_arbitrary_precision/int_arbitrary_precision.cpp
        :language: cpp
        :lines: 2-6,125-134

Putting any C++ arbitrary precision types in a comma separated list will generate a concatenation. 
The concatenation can currently be used to create arbitrary precision types (zero extending or truncating to match widths), but can not be assigned to.


.. _ap_fixpt:

C++ Arbitrary Precision Fixed Point Library
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The C++ Arbitrary Precision Fixed Point library provides fast bit accurate software simulation, and efficient equivalent
hardware generation. The C++ ``ap_[u]fixpt`` types allow specifying signed and unsigned fixed point numbers of arbitrary width,
and arbitrary fixed position relative to the decimal. They can be used 
for arithmetic, concatenation, and bit level operations. You can use the ``ap_[u]fixpt`` type by including the
following header file.

.. literalinclude:: ../examples/user_guide_examples/fixed_arbitrary_precision/fixed_arbitrary_precision.cpp
	:language: cpp
	:lines: 2

The ``ap_[u]fixpt`` template allows specifying the width of the type, how far the most significant bit is above the decimal,
as well as several quantization and overflow modes. 

Quantization and overflow handling is triggered during assignment and construction. 
The policies used for quantization and overflow are based on the quantization and overflow modes of the
left hand side of an assignment, or of the value being constructed. 

The template ``ap_[u]fixpt<W, I_W, Q_M, O_M>`` is described in the following table. The last two template parameters are optional.

+----------+-------------------------------------------------------------+
| Parameter| Description                                                 |
+==========+=============================================================+
| W        | The width of the word in bits.                              |
+----------+-------------------------------------------------------------+
| I_W      | How far the most significant bit is above the decimal.      |
|          | I_W can be negative. I_W > 0 implies the MSB is above the   |
|          | decimal. I_W <= 0 implies the MSB is below the decimal.     |
|          |                                                             |
|          | If W >= I_W >= 0, then I_W is the number of bits used for   |
|          | the integer portion.                                        |
+----------+-------------------------------------------------------------+
| Q_M      | The Quantization(rounding) mode used when a result has      |
|          | precision below the least significant bit.                  |
|          |                                                             |
|          | Defaults to AP_TRN.                                         |
|          +----------------+--------------------------------------------+
|          | AP_TRN         | Truncate bits below the LSB bringing the   |
|          |                | result closer to -∞.                       |
|          +----------------+--------------------------------------------+
|          | AP_TRN_ZERO    | Truncate bits below the LSB bringing the   |
|          |                | result closer to zero.                     |
|          +----------------+--------------------------------------------+
|          | AP_RND         | Round to the nearest representable value   |
|          |                | with the midpoint going towards +∞.        |
|          +----------------+--------------------------------------------+
|          | AP_RND_INF     | Round to the nearest representable value   |
|          |                | with the midpoint going towards -∞ for     |
|          |                | negative numbers, and +∞ for positive      |
|          |                | numbers.                                   |
|          +----------------+--------------------------------------------+
|          | AP_RND_MIN_INF | Round to the nearest representable value   |
|          |                | with the midpoint going towards -∞.        |
|          +----------------+--------------------------------------------+
|          | AP_RND_ZERO    | Round to the nearest representable value   |
|          |                | with the midpoint going towards 0.         |
|          +----------------+--------------------------------------------+
|          | AP_RND_CONV    | Round to the nearest representable value   |
|          |                | with the midpoint going towards the        |
|          |                | nearest even multiple of the quantum.      |
|          |                | (This helps to remove bias in rounding).   |
+----------+----------------+--------------------------------------------+
| O_M      | The Overflow mode used when a result exceeds the maximum or |
|          | minimum representable value.                                |
|          |                                                             |
|          | Defaults to AP_WRAP.                                        |
|          +----------------+--------------------------------------------+
|          | AP_WRAP        | Wraparound between the minimum and maximum |
|          |                | representable values in the range.         |
|          +----------------+--------------------------------------------+
|          | AP_SAT         | On positive and negative overflow saturate |
|          |                | the result to the maximum or minimum value |
|          |                | in the range respectively.                 |
|          +----------------+--------------------------------------------+
|          | AP_SAT_ZERO    | On any overflow set the result to zero.    |
|          +----------------+--------------------------------------------+
|          | AP_SAT_SYM     | On positive and negative overflow saturate |
|          |                | the result to the maximum or minimum value |
|          |                | in the range symmetrically about zero.     |
|          |                |                                            |
|          |                | For ap_ufixpt this is the same as AP_SAT.  |
+----------+----------------+--------------------------------------------+

An ``ap_[u]fixpt`` is a W bit wide integer, in 2's complement for the signed case, which
has some fixed position relative to the decimal. This means that arithmetic is efficiently
implemented as integer operations with some shifting to line up decimals. Generally a 
fixed point number can be thought of as a signed or unsigned integer word multiplied by 2^(I_W - W).
The range of values that an ``ap_[u]fixpt`` can take on, as well as the quantum that
separates those values is determined by the W, and I_W template parameters. The AP_SAT_SYM
overflow mode forces the range to be symmetrical about zero for signed fixed point types.   
This information is described in the following table. Q here represents the quantum.

+----------+-------------------+-----------------------+------------------------+
| Type     | Quantum           | Range                 | AP_SAT_SYM Range       |
+----------+-------------------+-----------------------+------------------------+
| ap_ufixpt| 2^(I_W - W)       | 0                     | 0                      |
|          |                   |                       |                        |
|          |                   | to                    | to                     |
|          |                   |                       |                        |
|          |                   | 2^(I_W) - Q           | 2^(I_W) - Q            |
+----------+-------------------+-----------------------+------------------------+
| ap_fixpt | 2^(I_W - W)       | -2^(I_W - 1)          | -2^(I_W - 1) + Q       |
|          |                   |                       |                        |
|          |                   | to                    | to                     |
|          |                   |                       |                        |
|          |                   | 2^(I_W - 1) - Q       | 2^(I_W - 1) - Q        |
+----------+-------------------+-----------------------+------------------------+

Some ``ap_[u]fixpt`` ranges are demonstrated in the following table.

+-------------------+--------------+-----------------+
| Type              | Quantum      | Range           |
+-------------------+--------------+-----------------+
| ap_fixpt<8, 4>    | 0.0625       | -8 to 7.9375    |
+-------------------+--------------+-----------------+
| ap_ufixpt<4, 12>  | 256          | 0 to 3840       |
+-------------------+--------------+-----------------+
| ap_ufixpt<4, -2>  | 0.015625     | 0 to 0.234375   |
+-------------------+--------------+-----------------+

An example using ``ap_fixpt`` is show below.

.. literalinclude:: ../examples/user_guide_examples/ap_fixpt_example/ap_fixpt_example.cpp
	:language: cpp
	:lines: 1,2,4-14,19-50

This example implements a streaming FIR filter with 8 taps. Using the minimum width ``ap_fixpt`` to represent
the constant coefficients allows the multiply to happen at a smaller width than if they were the same (wider)
type as the inputs. This example ensures that no overflows occur by always assigning to an ``ap_fixpt`` that uses the AP_SAT
overflow mode. This does incur a performance penalty, but this is minimized here by accumulating the results in a binary
fashion, such that there are only log(TAPS) = 3 saturating operations that depend on each other. If the results were
accumulated in a single variable in one loop then there would be TAPS = 8 saturating operations depending on each other.
Having more saturating operations in a row is slower because at each step overflow needs to be checked before the next 
operation can occur.

Printing ap_[u]fixpt Types
++++++++++++++++++++++++++++

The Arbitrary Precision Fixed Point Library provides some utilities for printing ``ap_[u]fixpt`` types in software, demonstrated below. 
The ``to_fixpt_string(base, signedness)`` function takes an optional base argument which is one of 2, 10, or 16, and defaults to 10,
as well as an optional signedness argument which determines if the data should be treated as signed or unsigned. The signedness argument defaults to false
for ap_ufixpt, and true for ap_fixpt. 

The output stream operator ``<<`` can be used to put a fixed point number into an output stream
as if it were called with the default ``to_fixpt_string`` arguments.

The ``to_double()`` function can be useful for printing, but it can lose precision over a wide fixed point. It can be used
in hardware, but this is expensive, and should be avoided when possible.

.. literalinclude:: ../examples/user_guide_examples/fixed_arbitrary_precision/fixed_arbitrary_precision.cpp
	:language: cpp
	:lines: 2-7,10-29

Initializing ap_[u]fixpt Types
+++++++++++++++++++++++++++++++

The ``ap_[u]fixpt`` types can be constructed and assigned from other fixed points, the ``ap_[u]int`` types, C++ integer and floating
point types, as well as concatenations and bit selections. They can also be initialized from a hexadecimal string describing the exact
bits. Note that construction and assignment will always trigger the quantization and overflow handling of the ``ap_[u]fixpt`` being constructed or assigned to, 
except when copying from the exact same type, or initializing from a hexadecimal string. For logical assignments of bits, bit selection assignments can be used, as well as
the ``from_raw_bits`` function, or the ``ap_[u]int`` ``to_fixpt<I_W>()`` functions in the case of ``ap_[u]int`` types.

.. NOTE::

  Initializing ``ap_[u]fixpt`` types from floating point types in hardware is expensive, and should be avoided when possible. However, initializing
  ``ap_[u]fixpt`` from floating point literals is free, and happens at compile time.

Some examples of initializing fixed point types are shown in the following code snippet.

.. literalinclude:: ../examples/user_guide_examples/fixed_arbitrary_precision/fixed_arbitrary_precision.cpp
	:language: cpp
	:lines: 1-7,30-74

Arithmetic With ap_[u]fixpt Types
++++++++++++++++++++++++++++++++++
The Arbitrary Precision Fixed Point library supports all standard arithmetic, logical bitwise, shifts, and comparison
operations. During arithmetic intermediate results are kept in a wide enough type to hold all of the possible resulting values. Operands
are shifted to line up decimal points, and sign or zero extended to match widths before an operation is performed. For fixed
point arithmetic, whenever the result of a calculation can be negative the intermediate type is an ``ap_fixpt`` instead of ``ap_ufixpt``
regardless of whether any of the operands were ap_fixpt.
Overflow and quantization handling only happen when the result is assigned to a fixed point type.

.. NOTE::

  Overflow and quantization handling is not performed for any assigning shifting operations (<<=, >>=) on ``ap_[u]fixpt`` types.
  Also, non-assigning shifts (<<, >>, .ashr(x)) do not change the width or type of the fixed point they are applied to. This means that bits can be shifted out of
  range.

Fixed point types can be mixed freely with other arbitrary precision and c++ numeric types for arithmetic, logical bitwise, and comparison operations,
with some caveats for floating point types.

.. NOTE::

  For arithmetic and logical bitwise operations floating point types **must** be explicitly cast to an ``ap_[u]fixpt`` type before
  being used, because of the wide range of possible values the floating point type could represent. It is also a good idea, but not required, to
  use ``ap_[u]int`` types in place of C++ integers when less width is required.

.. NOTE::
  For convenience floating point types can be used directly in fixed point comparisons, however floating points are truncated
  and wrapped as if they were assigned to a signed ``ap_fixpt`` just big enough to hold all values of the ``ap_[u]fixpt``
  type being compared against, with the AP_TRN and AP_WRAP modes on.

An example demonstrating some of this behaviour is show below.

.. literalinclude:: ../examples/user_guide_examples/fixed_arbitrary_precision/fixed_arbitrary_precision.cpp
	:language: cpp
	:lines: 2-7, 75-101

Explicit Conversions of ap_[u]fixpt 
++++++++++++++++++++++++++++++++++++++++++++
There are several functions to explicitly convert ``ap_[u]fixpt`` types into other types, besides value based assignments. The ``raw_bits`` function produces a uint of
the same width as the ap_[u]fixpt with the same raw data, and to_double returns a double representing the value of the ap_[u]fixpt. Note that 
for wide enough ap_[u]fixpt to_double can lose precision, and can be inefficient in hardware. These are demonstrated in the
following code snippet.

.. literalinclude:: ../examples/user_guide_examples/fixed_arbitrary_precision/fixed_arbitrary_precision.cpp
	:language: cpp
	:lines: 2-7,102-110

Supported Operations in ap_[u]int, ap_[u]fixpt, and floating-point
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The table below shows all the standard arithmetic operations that are supported in 
our Arbitrary Precision Integer and Fixed Point Libraries as well as for 
floating-point data types. It also shows some useful APIs that can be used to
convert from one type to another or to convert to standard integral types or strings. 


+-----------+------------------------+----------------+-----------+-------------+----------+
| Type      | Operator               | Description    | ap_[u]int | ap_[u]fixpt | floating |
+-----------+------------------------+----------------+-----------+-------------+----------+
| Arithmetic|   \+                   | Addition       |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \-                   | Subtraction    |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \*                   | Multiplication |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \/                   | Division       |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \%                   | Modulo         |     Y     |      Y      |Note Below|
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \++                  | Increment      |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \--                  | Decrement      |     Y     |      Y      |    Y     |
+-----------+------------------------+----------------+-----------+-------------+----------+
| Assignment|   \=                   | Assignment     |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \+=                  | Add and assign |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \-=                  | Sub and assign |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \*=                  | Mult and assign|     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \/=                  | Div and assign |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \%=                  | Mod and assign |     Y     |      Y      |Note Below|
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \&=                  | bitwise AND    |     Y     |      Y      |    N/A   |
|           |                        | and assign     |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \|=                  | Bitwise OR     |     Y     |      Y      |    N/A   |
|           |                        | and assign     |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \^=                  | Bitwise XOR    |     Y     |      Y      |    N/A   |
|           |                        | and assign     |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \>>=                 | SHR and assign |     Y     |      Y      |    N/A   |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \<<=                 | SHL and assign |     Y     |      Y      |    N/A   |
+-----------+------------------------+----------------+-----------+-------------+----------+
| Comparison|   \==                  | Equal to       |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \!=                  | Not equal to   |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \>                   | Greater than   |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \<                   | Less than      |     Y     |      Y      |    Y     |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \>=                  | Greater than   |     Y     |      Y      |    Y     |
|           |                        | or equal to    |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \<=                  | Less than      |     Y     |      Y      |    Y     |
|           |                        | or equal to    |           |             |          |
+-----------+------------------------+----------------+-----------+-------------+----------+
| Bitwise   |   \&                   | Bitwise AND    |     Y     |      Y      |    N/A   |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \^                   | Bitwise XOR    |     Y     |      Y      |    N/A   |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \|                   | Bitwise OR     |     Y     |      Y      |    N/A   |
|           +------------------------+----------------+-----------+-------------+----------+
|           |   \~                   | Bitwise Not    |     Y     |      Y      |    N/A   |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .or_reduce()           | Bitwise OR     |     Y     |      Y      |    N/A   |
|           |                        | reduction      |           |             |          |
+-----------+------------------------+----------------+-----------+-------------+----------+
|  Shift    | <<                     | Shift left     |     Y     |      Y      |    N/A   |
|           +------------------------+----------------+-----------+-------------+----------+
|           | >>                     | Shift right    |     Y     |      Y      |    N/A   |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .ashr(ap_uint numbits) | Arithmetic     |     Y     |      Y      |    N/A   |
|           |                        | shift right    |           |             |          |
+-----------+------------------------+----------------+-----------+-------------+----------+
| Bit level | num(a, b)              | Range          |     Y     |      Y      |    N/A   |
| access    |                        | selection      |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | num.range(a, b)        | Range          |     Y     |      Y      |    N/A   |
|           |                        | selection      |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | num\[a\]               | Bit            |     Y     |      Y      |    N/A   |
|           |                        | selection      |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | num.byte(n, s = 8)     | Select ``n-th``|     Y     |      Y      |    N/A   |
|           |                        | byte with      |           |             |          |
|           |                        | ``s`` bits per |           |             |          |
|           |                        | byte           |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | (numa, numb, numc)     | Concat         |     Y     |      Y      |    N/A   |
+-----------+------------------------+----------------+-----------+-------------+----------+
| Explicit  | .to_ufixpt()           | Convert to     |     Y     |      N/A    |    N/A   |
| Conversion|                        | ap_ufixpt      |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .to_fixpt()            | Convert to     |     Y     |      N/A    |    N/A   |
|           |                        | ap_fixt        |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .to_uint64()           | Convert to     |     Y     |      N/A    |    N/A   |
|           |                        | uint64         |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .to_int64()            | Convert to     |     Y     |      N/A    |    N/A   |
|           |                        | int64          |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .raw_bits()            | Convert to     |     N/A   |      Y      |    N/A   |
|           |                        | raw bits       |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .from_raw_bits()       | Convert from   |     N/A   |      Y      |    N/A   |
|           |                        | raw bits       |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .to_double()           | Convert to     |     N/A   |      Y      |    N/A   |
|           |                        | double         |           |             |          |
+-----------+------------------------+----------------+-----------+-------------+----------+
| String    | .to_fixpt_string()     | Convert to     |     N/A   |      Y      |    N/A   |
| Conversion|                        | fixpt string   |           |             |          |
|           +------------------------+----------------+-----------+-------------+----------+
|           | .to_string()           | Convert to     |     Y     |      Y      |    N/A   |
|           |                        | int string     |           |             |          |
+-----------+------------------------+----------------+-----------+-------------+----------+

.. NOTE::
  To use floating point remainder, call the ``fmod`` or ``fmodf`` function from the <math.h> header.
  
  Note that the floating-point remainder core can be very large when used in a pipeline, so it should be 
  used with care. For the same reason, floating point remainder is only directly supported for 
  the float type. For double, the inputs to the core will be cast down to float,
  and the result will be cast back to double. This can result in a loss of precision, 
  or incorrect results when the double input is not representable in the range of float.


Image Processing Library
~~~~~~~~~~~~~~~~~~~~~~~~~~
The SmartHLS image processing library provides C++ class/function APIs for a
number of commonly used image processing operations.
You can use these class/function APIs by including the following header file,

.. code-block:: CPP

    #include "hls/image_processing.hpp"

.. _line_buffer_user_guide:

Line Buffer
++++++++++++++++++++++
The ``LineBuffer`` class implements the line buffer structure that is commonly
seen in image convolution (filtering) operations, where a filter kernel is
"slided" over an input image and is applied on a local window (e.g., a square)
of pixels at every sliding location.  As the filter is slided across the image,
the line buffer is fed with a new pixel at every new sliding location while
retaining the pixels of the previous image rows that can be covered for the
sliding window.
The public interface of the ``LineBuffer`` class is shown below,

.. code-block:: CPP

  template <typename PixelType, unsigned ImageWidth, unsigned WindowSize>
  class LineBuffer {
    public:
      PixelType window[WindowSize][WindowSize];
      void ShiftInPixel(PixelType input_pixel);
  };

Below shows an example usage of the LineBuffer class:

* Instantiate the line buffer in your C++ code, with template
  arguments being the pixel data type, input image width, and sliding window
  size.  The window maintained by the line buffer assumes a square
  ``WindowSize x WindowSize`` window.  If you are instantiating the line buffer
  inside a pipelined function (accepting a new pixel in every function call),
  you will need to add 'static' to make the line buffer static.

.. code-block:: CPP

 static hls::LineBuffer<unsigned char, ImageWidth, WindowSize> line_buffer;

* Shift in a new pixel by calling the ``ShiftInPixel`` method:

.. code-block:: CPP

   line_buffer.ShiftInPixel(input_pixel);

* Then your filter can access any pixels in the ``window`` by:

.. code-block:: CPP

  line_buffer.window[i][j]

The figure below illustrates how the line buffer ``window`` is being updated
after each call of ``ShiftInPixel``.  You will notice that the `window` can
contain out-of-bound pixels at certain sliding locations.

.. The figure comes from this pptx: https://microchiptechnology-my.sharepoint.com/:p:/g/personal/lanny_lian_microchip_com/EdzCkAV3CplOtwwyS4QJ3GEBGfYfcugl8OOUt4vN1baTlg?e=zSoAmg
.. image:: /images/LineBufferClass.png
        :scale: 90 %
        :align: center

For more details about when/why to use the ``LineBuffer`` class, see
:ref:`line_buffer_opt_guide` in the :ref:`optimizationguide`.
   


.. Comment out pure software flow:
  Pure Software Flow
  ------------------

  SmartHLS also has a pure software flow that can be used for testing your C code.
  The pure software flow works for both MIPS and ARM processors.
  To target a specific processor architecture, SmartHLS makes sure an appropriate project
  has been selected in ``smarthls/examples/legup.tcl``.

  The SmartHLS script is shls. The following shls targets are relevant to the pure software flow:
   * ``shls sw``: generate an ELF file for the desired processor architecture
   * ``shls swsim``: compile the application and simulate it with ModelSim (MIPS only)
   * ``shls simulation``: simulate execution of the application on the processor using ModelSim (``make sw`` must have been run previously)(MIPS only)
   * ``shls simulation_with_wave``: simulate execution of the application on the processor using ModelSim, with waveforms (``make sw`` must have been run previously)(MIPS only)
   * ``shls run_on_board``: run the application on the board (``make sw`` must have been run previously)(ARM only)
   * ``shls emul``: compile and run the application in an emulator: gxemul for MIPS and QEMU for ARM

.. end SW Flow


.. _c_math_library:

Math Library (math.h)
~~~~~~~~~~~~~~~~~~~~~~

SmartHLS supports a subset of the C Math Library. These functions are supported for functionality, however, may not lead to an efficient hardware implementation.
If you require high performance, we recommend restructuring your software code to not call these math functions. 
The table below shows supported math functions.

+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Function Types                                                  | Function Names                                                                                             |
+============================+====================================+============================================================================================================+
| Trigonometric functions                                         | cos, cosf, sin, sinf, tan, tanf, acos, acosf, asin, asinf, atan, atanf, atan2                              |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Hyperbolic functions                                            | cosh, coshf, sinh, sinhf, tanh, tanhf, acosh, acoshf, asinh, asinhf, atanh, atanhf                         |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Exponential and logarithmic functions                           | exp, expf, frexp, log, logf, log10, modf, exp2, expm1, ilogb, log1p, log2, logb, scalbn, scalbln           |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Power functions                                                 | pow, powf, sqrt, hypot, cbrt                                                                               |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Error and gamma functions                                       | erf, erfc, tgamma                                                                                          |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Rounding and remainder functions                                | ceil, floor, fmod, fmodf, trunc, round, lround, llround, rint, lrint, llrint, nearbyint, remainder, remquo |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Floating-point manipulation functions                           | copysign, nan, nextafter                                                                                   |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Minimum, maximum, difference functions                          | fdim, fmax, fmin                                                                                           |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Other functions                                                 | fabs, fabsf, fma                                                                                           |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+
| Implemented as macros in C | Classification macros or functions | isinf, isnan                                                                                               |
| and as functions in C++    +------------------------------------+------------------------------------------------------------------------------------------------------------+
|                            | Comparison macros or functions     | isgreater, isgreaterequal, isless, islessequal, islessgreater                                              |
+----------------------------+------------------------------------+------------------------------------------------------------------------------------------------------------+

.. _allocation_library:

Memory Allocation Library
~~~~~~~~~~~~~~~~~~~~~~~~~~~
For SoC designs on platforms running Linux, the SmartHLS Memory Allocation Library can be used to allocate memory in special areas outside of the areas normally used by the operating system.
Memory in these areas is guaranteed to be physically contiguous and free from the virtual-physical mapping that is normally imposed by the operating system. 
Having contiguous, physically pinned down memory is required for efficient memory transfers between DDR and components on the FPGA fabric, since it avoids issues such as paging and virtual-to-physical address translation.
The SmartHLS memory allocation library should be used for any accelerator arguments that use DMA Copy or Accelerator Direct Access :ref:`soc_data_transfer_methods`.
An Example of how to use the library is shown below:


.. code-block:: CPP

	#include "hls/hls_alloc.h"

	// Allocate enough memory for an array of 8 32-bit numbers in the default memory
	// region using hls_malloc. This call has the same function signature as
	// standard C malloc().
	uint32_t array_size = 8 * sizeof(uint32_t);
	uint32_t *array_ptr = (uint32_t *)hls_malloc(array_size);

	// Allocate the same amount of memory in the non-cached DDR region. The second
	// optional argument is used to specify which memory region to use.
	uint32_t *noncached_array_ptr =
	(uint32_t *)hls_malloc(array_size, HLS_ALLOC_NONCACHED);

	// Use hls_memcpy to move data from one array to another. This call has the same
	// signature as standard C memcpy(), with additional arguments to specify where
	// the transfer is going and what method to use. In this example, we move data
	// from one array in MSS DDR to another array in MSS DDR, using the hard DMA
	// controller in the MSS.
	hls_memcpy(noncached_array_ptr, array_ptr, array_size, HLS_ALLOC_MSS_TO_MSS,
	HLS_ALLOC_PDMA);

	// Free the allocated buffers using hls_free, has the same function signuture as
	// standard C free().
	hls_free(array_ptr);
	hls_free(noncached_array_ptr);


The optional second argument in ``hls_malloc`` defines what memory region memory should be allocated in, and is of type ``hls_alloc_memory_type_t``, defined in the ``hls_alloc.h``.
Using the SmartHLS reference SoC linux image, there are three memory regions available for use with the Memory Allocation Library, oulined in the table below.
The address and size of each region can be modified to fit other Linux images by changing the ``hls_alloc_buffer_regions`` struct in ``hls_alloc.h`` and recompiling the library.

+-------------------------+------------+--------------+------------------------------------------------------------------------------------------------------------------------+
| Region                  | Address    | Size (bytes) | Description                                                                                                            |
+=========================+============+==============+========================================================================================================================+
| HLS_ALLOC_CACHED        | 0xae000000 | 0x02000000   | Cached DDR. Default if region unspecified. Recommended for best overall transfer times.                                |
+-------------------------+------------+--------------+------------------------------------------------------------------------------------------------------------------------+
| HLS_ALLOC_NONCACHED_WCB | 0xd8000000 | 0x08000000   | Non-cached DDR with write-combine buffer. Slightly better performance than Cached DDR for writes, but worse for reads. |
+-------------------------+------------+--------------+------------------------------------------------------------------------------------------------------------------------+
| HLS_ALLOC_NONCACHED     | 0xc0000000 | 0x08000000   | Non-cached DDR. Not recommended (lower performance than other options).                                                |
+-------------------------+------------+--------------+------------------------------------------------------------------------------------------------------------------------+

There are two extra arguments in ``hls_memcpy`` compared to the standard C ``memcpy``. The first extra argument is of type ``hls_alloc_direction_t``, and describes 
the direction in which data is moving, which is required by the underlying library to properly move data between the MSS DDR and buffers on the FPGA fabric.
The second extra argument is of type ``hls_alloc_transfer_type_t``, and allows the user to choose between two transfer methods. Selecting ``HLS_ALLOC_MEMCPY`` 
will invoke ``memcpy`` under the hood, and let the OS choose the best way to move the data. Selecting ``HLS_ALLOC_PDMA`` will use the platform DMA engine 
in the MSS to move the data. Argument types are defined as enums in ``hls_alloc.h``.

.. NOTE::

	The ``hls_memcpy`` function is automatically used as part of the accelerator driver generated by SmartHLS. Users are not expected to have to invoke this function to use SmartHLS accelerators.


.. include:: rtl_interface.inc

.. include:: accelerator_driver.inc

.. comment
    Software Profiler
    -------------------------------
    The SmartHLS IDE comes integrated with a profiler (``gprof``) that allows you to profile your software program to determine the runtime hot spots. 
    This information can be used to decide which program segment should be accelerated in hardware. 

    To use the profiler, one simply has to click the ``Profile Software`` button on an opened SmartHLS project:

    .. image:: /images/profiler_button.png
        :scale: 70%
        :align: center

    Alternatively, you could also click ``SmartHLS -> Profile Software`` on the top menu. 
    This executes the software program, and when it finishes running, a ``gprof`` tab
    should open up at the bottom window (where the ``Console`` window is). 

    .. image:: /images/profiler.png
        :scale: 100%
        :align: center


    The ``gprof`` tab shows a hierarchy of the percentage of runtime spent on executing the program. 
    In the figure shown above, you can see that most of the time is spent on executing the
    ``FIRFilterStreaming`` function. It also shows which parts of the function contribute
    to that percentage of runtime. Clicking on one of the lines (e.g., ``FIRFilterStreaming (fir.c:42)`` which contributes the highest percentage of runtime)
    takes you to that line of code in the IDE. 

    Using the software profiler is a useful way to determine which parts of your program is taking up the most runtime. 
    You can use this information to decide whether you want to accelerate that portion of code with SmartHLS, or re-write the code in software to be more efficient. 

    .. NOTE::
    Note that ``grof`` profiles a program based on samples that it takes, and its minimum sampling period is 10 ms. Hence if your program's runtime is very short, it will not give any meaningful result. 
    If this is the case, try to increase the runtime by providing more inputs to the program. 

    .. NOTE::
    The figure shown above for the profiled result is from SmartHLS running on Linux. On Windows, it shows a text-based result.  


    Using Pre-existing Hardware Modules
    -------------------------------

    It is possible to connect existing hardware modules to the hardware generated by SmartHLS.
    This can be useful when there are optimized IP blocks that one wants to use
    as part of a larger circuit. This is called the custom Verilog flow in SmartHLS.

    To use this, a wrapper C function needs to be created, where its prototype matches
    the module declaration of the custom Verilog module.
    The name of the C function needs to match the name of the Verilog module,
    and the C function must have the same number of arguments as the number
    of input ports of the Verilog module.
    The bit-widths of the function arguments also need to match the bit-widths of the input ports.
    In addition, the bit-width of the return type in C must match the width of the
    output port corresponding to the return value.

    To use the custom Verilog flow, one can specify the following in the ``config.tcl`` file:

    .. code-block:: tcl

  set_custom_rtl_function "function_name" noMemory
  set_custom_rtl_file "verilog_file_name"

    .. NOTE::
  Currently, a custom Ver module cannot access any memories. All arguments
  need to be passed in by value. It cannot be in a pipelined section (within a pipelined loop/function).
  In addition, a custom Ver module cannot invoke other modules (functions or other custom Ver modules).

    There can be cases where a custom Verilog module needs to access I/Os.
    However, accessing I/Os cannot be easily described in C.
    This can be done in SmartHLS by simply specifying the I/Os in the ``config.tcl`` file as the following:

    .. code-block:: tcl

  set_custom_rtl_function "function_name" noMemory \
    input/output high_bit:low_bit IO_signal_name
  set_custom_rtl_file "verilog_file_name"

    This connects the specified I/O signals of the custom Verilog module directly to the top-level module generated by SmartHLS.
    For example, if one specifies the following:

    .. code-block:: tcl

  set_custom_rtl_function "assignSwitchesToLEDs" noMemory \
    output 5:0 LEDR \
    input 5:0 SW \
    output 5:0 KEY
  set_custom_rtl_file "assignSwitchesToLEDs.v"

    This indicates to SmartHLS that it needs to connect ``LEDR``, ``SW``, and ``KEY`` ports directly to the ports of the top-level module generated by SmartHLS.

    Custom Verilog Module Interface
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    A custom Verilog module needs to conform to the interface expected by SmartHLS in order
    for it to be connected properly. The following interface is required by SmartHLS for the
    custom Verilog module:

 * ``input clk``: Clock signal for the custom Verilog module
 * ``input reset``: Reset signal for the custom Verilog module
 * ``input start``: Signal set to start the custom Verilog module (set high for 1 clock cycle)
 * ``output finish``: Set by the custom Verilog module to indicate the to rest of the SmartHLS-generated hardware that it has finished running.
 * ``return_val``: Only necessary if the wrapper C function has a return value. Its width must equal to the width of the return type in the C function.
 * ``arg_<argument_name> : Only necessary if the wrapper C function has an argument. The <argument_name> must the same as the name of the argument in
 the C wrapper function prototype, and its width must be equal to the bit-width of the argument type.

    In addition, a custom Verilog module may have ports that directly to I/Os, as described above.
    However, as these ports are not specified in C, they do not have to follow any C conventions.
    SmartHLS will create ports at the top-level module with the user-specified names and widths, and connect
    them directly to the custom Verilog module.

.. _custom_testbench:

Specifying a Custom Test Bench
-------------------------------

SmartHLS allows one to use a custom test bench to simulate the hardware generated by SmartHLS.
When a top-level function other than ``main`` is specified by the user, there are two options for simulation:

* Use :ref:`sw_hw_cosimulation`.
* A custom test bench must be provided by the user.

A custom test bench can be specified to SmartHLS via the ``HLS Constraints`` window:

.. image:: /images/set_custom_test_bench.png
        :scale: 100 %
        :align: center

One must specify both the name of custom Verilog module as well as the name of the custom test bench file.
It can also be specified directly in the ``config.tcl`` file as the following:

.. code-block:: tcl

  set_custom_test_bench_module "testBenchModuleName"
  set_custom_test_bench_file "testBenchFileName.v"

This constraint is also described in :ref:`set_custom_test_bench_module` and :ref:`set_custom_test_bench_file`.

Synthesize Hardware to FPGA
-------------------------------

SmartHLS can run Libero to report FPGA resource and timing information.
There are two options for ``Synthesize Hardware to FPGA``:

    1. RTL synthesis only for resource results (faster runtime).
    2. RTL synthesis, place and route, for resource and timing results (slower runtime).

The following synthesis settings are used by SmartHLS:

  * Enable Retiming: Yes
  * Map ROM components to: RAM
  * Additional options for Synplify: set_option -maxfan 30

The following place and route settings are used by SmartHLS:

  * High effort layout: Yes

The Libero project will use block flow (-block_mode 1) to compile the generated IP core in isolation.

For more details, see the following Tcl script that SmartHLS uses to run Libero synthesis, place and route:
``<SMARTHLS_INSTALLATION_DIR>\SmartHLS\examples\synthesize_microsemi.tcl``


.. include:: soc_features.inc

.. include:: soc_profiler.inc

.. include:: smarthls_report.inc

.. include:: schedule_viewer.inc

.. include:: hdl_plus.inc

.. include:: soc_integration.inc

.. include:: smarthls_outputs.inc

.. _cmdline:

SmartHLS Command Line Interface
----------------------------------

In addition to the SmartHLS IDE, there is also a command line tool (``shls``) available to call 
SmartHLS from a terminal, or from a user script for the purposes of automation. 

.. _windows_cmdline:

Launch Cygwin terminal on Windows
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Windows users can launch the terminal by opening ``<SMARTHLS_INSTALLATION_DIR>/cygwin64/Cygwin.bat``.
Users can access their file directory on their computer by using ``/cygdrive/<drive letter>/<path>``
as the prefix.
For example, to go to ``C:\Microchip\SmartHLS-2022.2.1``, enter ``cd /cygdrive/c/Microchip/SmartHLS-2022.2.1``.

Setup
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

To run SmartHLS from the command line, your ``PATH`` environment variable should contain the paths to:

  * ``shls``: SmartHLS executable.
  * ``vsim``: Modelsim's executable for HW simulation and SW/HW co-simulation.
  * ``libero``: Libero's executable for synthesis and Place & Route.  
  
Here's an example that you can adapt to your system:

.. code-block:: bash

  export PATH=<SMARTHLS_INSTALLATION_DIR>/SmartHLS/bin:$PATH
  export PATH=<LIBERO_SOC_INSTALLATION_DIR>/ModelSimPro/modeltech/bin:$PATH
  export PATH=<LIBERO_SOC_INSTALLATION_DIR>/Libero/bin:$PATH

SmartHLS comes with a bash script to provide autocompletion when using the command line on a Linux terminal.
It can be sourced like this:

.. code-block:: bash

  source <SMARTHLS_INSTALLATION_DIR>/SmartHLS/examples/scripts/utils/autocomplete/bash_autocomplete.sh

After that you can start typing ``shls`` plus a space, then hit the ``<TAB>`` key and a list of available commands 
will be displayed. If you continue typing the command and hit the ``<TAB>`` key again the command will be autocompleted.

Commands
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Here is the list of available commands:

.. code-block:: bash

    shls [-h] <cmd>

Where ``<cmd>`` can be one of:

init
  Create a new SmartHLS project by generating a ``Makefile`` and a ``config.tcl`` file.

  * ``Makefile`` - this file has the following variables

      * ``SRCS``: This variable should list all the source files (``.cpp`` or ``.c``). 
        Header files should not be added to ``SRCS``, but should be properly included by the source files.
        ``shls init`` will automatically add the file names for the existing source files in the current directory.  
        If source files are created after ``shls init``, please update ``SRCS`` (e.g., ``SRCS = foo.cpp bar.cpp``).
      * ``NAME``: This variable stands for the project name, e.g., ``NAME = MY_PROJECT``.  The default 
        project name is the current directory name when ``NAME`` is not specified in ``Makefile``.
      * ``PROGRAM_ARGUMENTS``: This variable can be used to specify the arguments for the main() function, 
        which can be used for the software testbench (i.e., ``int main(int argc, char *argv[])``). 
        Here is an example: ``PROGRAM_ARGUMENTS = input_file.bmp golden_output_file.bmp``. 
        More details can be found in :ref:`sw_hw_cosimulation`.
    
      **NOTE**: the above variables should be specified before the last line in ``Makefile: include $(LEVEL)/Makefile.common``.

  * ``config.tcl`` - this file contains the project's configuration settings. Project parameters and constraints can be specified in this file as necessary. Please refer to the :ref:`constraints` page.

sw
  Compile and run the program in software on your host machine.  The compilation step is skipped if no change is detected in source/header files, ``Makefile`` and ``config.tcl``.

sw_compile
  Compile the program in software, the output is an executable file (``hls_output/.hls/<NAME>.sw_binary``).

sw_run
  Run the compiled executable (``hls_output/.hls/<NAME>.sw_binary``) on your host machine.

hw (default)
  Compile the software to hardware, the output is a set of Verilog HDL file (the HLS-generated IP core is in ``hls_output/rtl/<NAME>.v``, with additional RTL IP sub-modules named ``hls_output/rtl/<NAME>_*.v``).

cosim
  Run :ref:`sw_hw_cosimulation` to verify the generated circuit.

cosim_wave
  Same as ``cosim`` but with ModelSim waveform.

sim
  Simulate the generated hardware in ModelSim (for an input software that has no top-level function specified, which is uncommon).

wave
  Same as above but with ModelSim waveform.

fpga
  Synthesize the generated hardware to target FPGA. This runs RTL synthesis and place-and-route for resource and timing results.

rtl_synth
  Run RTL synthesis for resource results. This will take less time than **fpga**.

scheduleviewer
  Show the scheduler viewer.

logic_level_histogram
  Generates a plot of the logic levels distribution of the synthesized design based on the timing analysis report.
  
clean
  Delete files generated by SmartHLS.

soc_*
  SoC-specific commands are prefixed with "soc\_" and are outlined in the table below:

  .. NOTE::

      This feature is specific to SmartHLS SoC early access program (EAP), and requires a separate SmartHLS EAP license. If you are interested in participating in the EAP, please email SmartHLS@microchip.com.


.. The soc_base_proj_generate target is internal and there is no button in GUI.
.. | `soc_base_proj_generate`   | Generates a basic PolarFire SoC project in Libero/SmartDesign, containing an Icicle MSS component.

+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Command                    | Description                                                                                                                                                            |
+============================+========================================================================================================================================================================+
| `soc_base_proj_program`    | Programs a pre-built base project bitstream to an attached Icicle Kit.                                                                                                 |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_sw_compile_no_accel`  | Cross-compiles user software (with no accelerators) to a binary targeting the RISC-V processor on PolarFire SoC.                                                       |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_base_proj_run`        | Moves the RISC-V binary generated by `soc_sw_compile_no_accel` to an Icicle Kit on the network and runs the binary on the Icicle kit.                                  |
|                            | Requires the BOARD_IP environment variable to be set.                                                                                                                  |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_accel_proj_generate`  | Generates a reference SoC Libero/SmartDesign project, containing an MSS connected to SmartHLS-generated hardware accelerators.                                         |
|                            | Please see :ref:`reference_soc_arch` for more information.                                                                                                             |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_accel_proj_rtl_synth` | Runs RTL synthesis on the generated reference SoC project. Reports resource utilization (see `Report Files`_).                                                         |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_accel_proj_pnr`       | Runs place and route on the generated reference SoC project. Reports resource utilization and timing result (see `Report Files`_).                                     |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_accel_proj_program`   | Programs the generated reference SoC project to an attached Icicle Kit. Requires PROGRAMMER_ID environment variable to be set.                                         |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_sw_compile_accel`     | Transforms user software by replacing top-level function calls with calls to the :ref:`hardware accelerator driver functions<top_level_driver_functions>`,             |
|                            | and cross-compiles the transformed software to a binary targeting the RISC-V processor on PolarFire SoC.                                                               |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_accel_proj_run`       | Moves the RISC-V binary generated by `soc_sw_compile_accel` to an Icicle Kit on the network and runs the binary on the Icicle kit.                                     |
|                            | Requires the BOARD_IP environment variable to be set.                                                                                                                  |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| `soc_profiler_view`        | Displays a runtime plot and prints a summary table of the profiling data gathered during runtime execution for each accelerator in the project.                        |
+----------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

.. Commands for the hybrid flow:
..   * **hybrid**: Run the hybrid flow.
..   * **hybrid_compile**: Synthesize the generated SoC to FPGA bitstream with Libero SoC (``shls hybrid`` must have been run previously)
..   * **shls program_board**: Program the FPGA with the generated bitstream (.sof) file (``shls hybrid_compile`` must have been run previously)
..   * **shls run_on_board**: Download and run the program on FPGA (``shls program_board`` must have been run previously)

.. Other commands for the hardware flow are:
..
..  * **make sw**: run in software
..  * **make w**: simulate the output Verilog file with ModelSim and show waveforms
..  * **make p**: create a Libero project in the current directory
..  * **make q**: run the synthesis mapper on the Verilog file
..  * **make f**: run a full Libero compile Verilog file
..  * **make watch**: debug the hardware implementation by comparing a ModelSim simulation trace to a pure software trace. See :ref:`watch`.
..  * **make dot**: compile all .dot graph files in the current directory into .ps files
..
.. A few other useful commands for the hybrid and software only flows are:
..
..  * **make hybridsim**: run the hybrid flow and simulate the output Verilog with ModelSim
..  * **make swsim**: run the software only flow and simulate the MIPS processor executing the software with ModelSim
..  * **make emul**: simulate MIPS assembly on GXemul MIPS emulator


.. _sw_macro:

Software Macros
--------------------

.. _synthesis_macro:

``__SYNTHESIS__`` Macro
~~~~~~~~~~~~~~~~~~~~~~~~~~
The ``__SYNTHESIS__`` macro is defined in SmartHLS during synthesis. This provides a convenient way to exclude non-synthesizable code without removing/commenting the code itself. In the folling example, the assertion header and statement are ignored during synthesis:

.. code-block:: c

  #ifndef __SYNTHESIS__
  #include <assert.h>
  #endif

  void func(int A[10], int N) {
  #pragma HLS function top

  #ifndef __SYNTHESIS__
    assert(N < 10);
  #endif

    return A[N];
  }

.. Note::

  While the ``__SYNTHESIS__`` macro is useful to exclude debugging and system calls, it can change the results between the software and the synthesized Verilog if the excluded code changes the functionality. This can introduce errors or unexpected behaviour in simulation / co-simulation. Use the ``__SYNTHESIS__`` macro carefully and make sure it does not change the functionality.
  
``HAS_ACCELERATOR`` Macro
~~~~~~~~~~~~~~~~~~~~~~~~~~

.. NOTE::

    This feature is specific to SmartHLS SoC early access program (EAP), and requires a separate SmartHLS EAP license. If you are interested in participating in the EAP, please email SmartHLS@microchip.com.

For SoC projects where different code needs to be called depending on if hardware accelerators are used, the ``HAS_ACCELERATOR`` macro can be used. For example, SoC accelerators using DMA transfer
need their argument buffers to be initialized using ``hls_alloc`` (see `Memory Allocation Library`_), where as when the function is not accelerated (the software version is run), a simple ``malloc`` will suffice.


.. code-block:: c

	#ifdef HAS_ACCELERATOR
	// Set up a hardware-specific buffer
	int * InputBuffer = hls_alloc(...);
	...
	#else
	// Set up a software-specific buffer
	int * InputBuffer = malloc(...);
	...
	#endif
	
	accelearted_function(InputBuffer);


``COSIM_EARLY_EXIT`` Macro
~~~~~~~~~~~~~~~~~~~~~~~~~~~~
For projects that invoke accelerated functions many times, Co-Simulation can take a long time due to simulating each accelerated function call. The ``COSIM_EARLY_EXIT`` macro can be used
to trigger an early exit for Co-Simulation only. For example, in the following code, Co-Simulation will only run the accelerator 10 times, while running in software or SoC-specific features will
run the accelerator 100 times.

.. code-block:: c

	for (int i = 0; i < 100; i++) {
	#ifdef COSIM_EARLY_EXIT
		if (i == 10) break;
	#endif
		// Call the accelerated function
		accelerated_function(...);
		...
	}

.. _makefile:

Makefile Variables
-----------------------------

There are several Makefile variables that the compiler flow uses to compile the program. The description of each of them are listed below:
  
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| Variable              || Description                                                                                                                                           |
||                       ||                                                                                                                                                       |
+========================+========================================================================================================================================================+
|| SRCS                  || The ``SRCS`` variable in ``Makefile`` should list all the source files (``.cpp`` or ``.c``).                                                          |
||                       || Header files should not be added to ``SRCS``, but should be properly included by the source files.                                                    |
||                       || ``shls init`` will automatically add the file names for the existing source files in the current directory.                                           |
||                       || If source files are created after ``shls init``, please update ``SRCS`` (e.g., ``SRCS = foo.cpp bar.cpp``).                                           |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| NAME                  || The ``NAME`` variable stands for the project name, e.g., ``NAME = MY_PROJECT``.                                                                       |
||                       || The default project name is the current directory name when ``NAME`` is not specified in ``Makefile``.                                                |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| BOARD_PATH            || Specify the path where the test will be run on board. The default is ``/home/root/``.                                                                 |
||                       || ``BOARD_PATH`` is always prefixed by ``/home/root/`` as programs are run as root on the board.                                                        |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| PROGRAM_ARGUMENTS     || ``PROGRAM_ARGUMENTS`` can be used to specify the arguments of the software testbench (i.e., ``int main(int argc, char *argv[])``).                    |
||                       || Here is an example: ``PROGRAM_ARGUMENTS = input_file.bmp golden_output_file.bmp``. More details can be found in :ref:`sw_hw_cosimulation`.            |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| NUM_LIBERO_PnR_PASSES || Defines the maximum number of Place and Route passes to go through in order to meet the timing requirement.                                           |
||                       ||                                                                                                                                                       |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| INPUT_FILES_RISCV     || Specifies the input files to the program to be copied to the development board, separated by a space.                                                 |
||                       || The path used for the files should be based on the path on the development local machine.                                                             |
||                       || For example:                                                                                                                                          |
||                       || ``INPUT_FILES_RISCV = lane3.avi lane3_golden.txt```                                                                                                   |
||                       || This will copy ``lane3.avi`` and ``lane3_golden.txt`` from the project folder to the Icicle board before running the program on board.                |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| OUTPUT_FILES_RISCV    || Specifies the output files of the program ran on the development board, separated by a space.                                                         |
||                       || The path used for the files should be based on the path on the development board.                                                                     |
||                       || Example:                                                                                                                                              |
||                       || ``OUTPUT_FILES_RISCV = output.avi output.txt`` will copy ``output.avi`` and ``output.txt``                                                            |
||                       || This will copy ``output.avi`` and ``output.txt`` from the the Icicle board to the project folder after running the program on board.                  |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| USER_CXX_FLAG         || Additional flags used for compilation such as ``-I``.                                                                                                 |
||                       || Example:                                                                                                                                              |
||                       || ``USER_CXX_FLAG = -I$(OPENCV_PATH)/include/opencv4``                                                                                                  |
||                       || The above compiler option will be added to all the compile command to include the OpenCV include directory.                                           |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| USER_CXX_FLAG_RISCV   || Additional flags used for compilation such as ``-I``.                                                                                                 |
||                       || USER_CXX_FLAG_RISCV is defaulted to USER_CXX_FLAG. Defining USER_CXX_FLAG_RISCV will override the default, including when it is defined but empty.    |
||                       || User can define this flag for adding specific flags for compiling the binary running on the on-board RISCV processor.                                 |
||                       || Example:                                                                                                                                              |
||                       || ``USER_CXX_FLAG_RISCV = -I$(OPENCV_PATH)/include/opencv4``                                                                                            |
||                       || The above compiler option will added to all the compile command to include the OpenCV include directory.                                              |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| USER_LINK_FLAG        || Flags for linking dynamic libraries such as ``-L`` and ``-l``.                                                                                        |
||                       || Example:                                                                                                                                              |
||                       || ``USER_LINK_FLAG = -L$(FFMPEG_PATH)/lib -lavcodec``                                                                                                   |
||                       || The above compiler option will link FFMPEG's avcodec library.                                                                                         |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| USER_LINK_FLAG_RISCV  || Flags for linking dynamic libraries such as ``-L`` and ``-l``.                                                                                        |
||                       || USER_LINK_FLAG_RISCV is defaulted to USER_LINK_FLAG. Defining USER_LINK_FLAG_RISCV will override the default, including when it is defined but empty. |
||                       || User can define this flag for adding specific flags for linking the binary running on the on-board RISCV processor.                                   |
||                       || Example:                                                                                                                                              |
||                       || ``USER_LINK_FLAG_RISCV = -L$(FFMPEG_PATH)/lib -lavcodec``                                                                                             |
||                       || The above compiler option will link FFMPEG's avcodec library for the RISCV processor.                                                                 |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| USER_ENV_VARS         || Set the enviromnent variable used for running the program on development host.                                                                        |
||                       || Example:                                                                                                                                              |
||                       || ``USER_ENV_VARS = LD_LIBRARY_PATH=$(OPENCV_PATH)/lib``                                                                                                |
||                       || The above compiler option will set ``LD_LIBRARY_PATH`` to ``$(OPENCV_PATH)/lib`` when running the program.                                            |
||                       || On Cygwin, users should specify ``PATH`` instead of ``LD_LIBRARY_PATH`` for linking libraries, like so:                                               |
||                       || ``USER_ENV_VARS = PATH=$(OPENCV_PATH)/bin``                                                                                                           |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+
|| USER_ENV_VARS_RISCV   || Set the enviromnent variable used for running the program on RISCV on the development board.                                                          |
||                       || USER_ENV_VARS_RISCV is defaulted to USER_ENV_VARS. Defining USER_ENV_VARS_RISCV will override the default, including when it is defined but empty.    |
||                       || Example:                                                                                                                                              |
||                       || ``USER_ENV_VARS_RISCV = LD_LIBRARY_PATH=$(OPENCV_PATH)/lib``                                                                                          |
||                       || The above compiler option will set ``LD_LIBRARY_PATH`` to ``$(OPENCV_PATH)/lib`` when running the program.                                            |
+------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------+

.. _makefile_example:

Makefile Example
~~~~~~~~~~~~~~~~~~~~~~~~~~~

The example below shows how to define some of the above Makefile variables.

For IDE projects, you should create a new ``Makefile.user`` file and put your custom Makefile settings there (any changes in the ``makefile`` of an IDE project will be overwritten).

.. literalinclude:: ../examples/microsemi/hybrid/icicle/lane_detect/Makefile.user
  :language: bash
  :lines: 15-



